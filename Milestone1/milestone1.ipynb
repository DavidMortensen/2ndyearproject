{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 1: Lyrics classification\n",
    "\n",
    "You will implement a text classifier that classifies song lyrics by era.\n",
    "\n",
    "You are expected to work on this milestone in lab 4-6.\n",
    "\n",
    "In particular, we created a dataset for you that consists of song lyrics from *rock bands* spanning the last half century!\n",
    "\n",
    "<img src=\"pics/cover.jpg\">\n",
    "\n",
    "*This assignment is adapted from material by J.Eisenstein*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "As for the last assignment,  you will need [python 3.6](https://www.python.org/downloads/) and the following libraries. Most if not all of these are part of [anaconda](https://www.continuum.io/downloads), so a good starting point would be to install that. \n",
    "\n",
    "- [jupyter](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- numpy (This will come if you install scipy like above, but if not install separately)\n",
    "- [matplotlib](http://matplotlib.org/users/installing.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "- [pandas](http://pandas.pydata.org/) Dataframes\n",
    "\n",
    "Make sure you have those installed both on your local computer and on your dedicated compute machine (assigned to you in lab 1).\n",
    "\n",
    "\n",
    "**Fork the repository** Fork the [course material repository](https://github.itu.dk/bapl/2ndyearproject-2019-material), i.e., create your own local copy in your own git repository. Develop your solution there. In the end, upload to the [shared course repository](https://github.itu.dk/bapl/2ndyearproject-2019) (where you uploaded your keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what is your course username? \n",
    "## Replace XX with your assigned number\n",
    "username=\"dsproj017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this assignment\n",
    "\n",
    "The assignment setup is similar to your language model assignment, i.e., \n",
    "- This is a Jupyter notebook. \n",
    "- Most of your coding will be in the python source files in the directory ```snlp```.\n",
    "- The directory ```tests``` contains unit tests which you should run to see that you're on the right track. \n",
    "- You may want to add more tests, but that is completely optional. \n",
    "- Code locally, push to your git repository and consider running computationally heavier parts on the assigned compute server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Python version\n",
      "python: 3.7.0 (default, Jun 28 2018, 07:39:16) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "print('My Python version')\n",
    "\n",
    "print('python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nose\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My library versions\n",
      "pandas: 0.23.4\n",
      "numpy: 1.15.4\n",
      "scipy: 1.2.0\n",
      "matplotlib: 2.2.3\n",
      "nose: 1.3.7\n",
      "keras: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "print('My library versions')\n",
    "\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('scipy: {}'.format(sp.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('nose: {}'.format(nose.__version__))\n",
    "print('keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether your libraries are the right version, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F\n",
      "======================================================================\n",
      "FAIL: test_environment.test_library_versions\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/davidmortensen/anaconda3/lib/python3.7/site-packages/nose/case.py\", line 197, in runTest\n",
      "    self.test(*self.arg)\n",
      "  File \"/Users/davidmortensen/2ndyearproject/Milestone1/tests/test_environment.py\", line 30, in test_library_versions\n",
      "    ok_(LooseVersion(sys.version) < LooseVersion(max_python)) # make sure not to use py3.7\n",
      "AssertionError: None\n",
      "-------------------- >> begin captured logging << --------------------\n",
      "matplotlib: DEBUG: $HOME=/Users/davidmortensen\n",
      "matplotlib: DEBUG: matplotlib data path /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data\n",
      "matplotlib: DEBUG: loaded rc file /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc\n",
      "matplotlib: DEBUG: matplotlib version 2.2.3\n",
      "matplotlib: DEBUG: interactive is False\n",
      "matplotlib: DEBUG: platform is darwin\n",
      "matplotlib: DEBUG: loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', 'posixpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', '_bootlocale', '_locale', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'sphinxcontrib', 'zope', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'nose', 'nose.core', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 'token', 'weakref', '_weakrefset', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'difflib', 'pprint', 'unittest.suite', 'unittest.loader', 'fnmatch', 'unittest.main', 'argparse', 'gettext', 'locale', 'unittest.runner', 'unittest.signals', 'signal', 'nose.config', 'optparse', 'textwrap', 'errno', 'configparser', 'nose.util', 'inspect', 'dis', 'opcode', '_opcode', 'nose.pyversion', 'nose.plugins', 'nose.plugins.base', 'nose.plugins.manager', 'nose.failure', 'pickle', 'struct', '_struct', '_compat_pickle', '_pickle', 'pkg_resources', '__future__', 'zipfile', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'binascii', 'pkgutil', 'platform', 'subprocess', '_posixsubprocess', 'select', 'selectors', 'math', 'plistlib', 'datetime', '_datetime', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'base64', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'random', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'socket', '_socket', 'urllib', 'urllib.parse', 'email._parseaddr', 'calendar', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources.extern.six', 'pkg_resources._vendor.six', 'pkg_resources.extern.six.moves', 'pkg_resources._vendor.six.moves', 'pkg_resources.py31compat', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging._compat', 'pkg_resources.extern.packaging.requirements', 'copy', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.six.moves.urllib', 'pkg_resources.extern.packaging.markers', 'sysconfig', '_osx_support', '_sysconfigdata_m_darwin_darwin', 'nose.plugins.plugintest', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'nose.loader', 'nose.case', 'nose.importer', 'imp', 'nose.selector', 'nose.suite', 'nose.proxy', 'nose.result', 'nose.exc', 'nose.plugins.skip', 'nose.plugins.errorclass', 'nose.plugins.deprecated', 'nose.tools', 'nose.tools.nontrivial', 'nose.tools.trivial', 'nose.plugins.builtin', 'nose.plugins.attrib', 'nose.plugins.capture', 'nose.plugins.logcapture', 'nose.plugins.cover', 'nose.plugins.debug', 'pdb', 'cmd', 'bdb', 'code', 'codeop', 'glob', 'nose.plugins.doctests', 'doctest', 'nose.plugins.isolate', 'nose.plugins.failuredetail', 'nose.inspector', 'nose.plugins.prof', 'nose.plugins.testid', 'nose.plugins.multiprocess', 'queue', '_queue', 'nose.plugins.xunit', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'xml.sax.saxutils', 'urllib.request', 'http', 'http.client', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'ssl', '_ssl', 'urllib.error', 'urllib.response', '_scproxy', 'nose.plugins.allmodules', 'nose.plugins.collect', 'test_environment', 'distutils', 'distutils.version', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._import_tools', 'numpy.add_newdocs', 'numpy.lib', 'numpy.lib.info', 'numpy.lib.type_check', 'numpy.core', 'numpy.core.info', 'numpy.core.multiarray', 'numpy.core.umath', 'numpy.core._internal', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'ntpath', 'ctypes', '_ctypes', 'ctypes._endian', 'numpy.core.numerictypes', 'numbers', 'numpy.core.numeric', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.shape_base', 'numpy.core.einsumfunc', 'numpy.testing', 'numpy.testing._private', 'numpy.testing._private.utils', 'gc', 'numpy.lib.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'numpy.testing._private.pytesttester', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.lib.function_base', 'numpy.lib.twodim_base', 'numpy.lib.histograms', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'ast', '_ast', 'numpy.linalg', 'numpy.linalg.info', 'numpy.linalg.linalg', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.stride_tricks', 'numpy.lib.mixins', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.scimath', 'numpy.lib.polynomial', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.core._multiarray_tests', 'numpy._distributor_init', 'numpy.fft', 'numpy.fft.info', 'numpy.fft.fftpack', 'numpy.fft.fftpack_lite', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random.info', 'cython_runtime', 'mtrand', 'numpy.random.mtrand', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'unicodedata', 'pandas.compat.chainmap', 'dateutil.parser', 'dateutil.parser._parser', 'six', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.parser.isoparser', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslib', 'pandas._libs.tslibs', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.np_datetime', '_cython_0_28_4', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.timestamps', 'pandas._libs.tslibs.fields', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.lib', 'pandas.core', 'pandas.core.config_init', 'pandas.core.config', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.printing', 'pandas.core.dtypes', 'pandas.core.dtypes.inference', 'pandas.io.formats.console', 'pandas.io.formats.terminal', 'pandas.core.api', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.common', 'pandas._libs.algos', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.missing', 'pandas.core.common', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.util._validators', 'pandas.core.arrays.categorical', 'pandas.core.accessor', 'pandas.core.base', 'pandas.core.nanops', 'bottleneck', 'bottleneck.reduce', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.move', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck.version', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'pandas.core.missing', 'pandas.core.groupby', 'pandas.core.groupby.groupby', 'pandas.core.index', 'pandas.core.indexes', 'pandas.core.indexes.api', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.frequencies', 'pandas._libs.tslibs.resolution', 'pandas.tseries', 'pandas.tseries.offsets', 'pandas.core.tools', 'pandas.core.tools.datetimes', 'dateutil.easter', 'pandas._libs.tslibs.offsets', 'pandas.tseries.frequencies', 'pandas._libs.join', 'pandas.core.ops', 'pandas._libs.ops', 'pandas.core.indexes.frozen', 'pandas.core.dtypes.concat', 'pandas.core.sorting', 'pandas.core.strings', 'pandas.core.indexes.category', 'pandas.core.indexes.multi', 'pandas.core.indexes.interval', 'pandas._libs.interval', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.numeric', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.range', 'pandas.core.indexes.period', 'pandas.core.frame', 'pandas.core.generic', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.internals', 'pandas._libs.internals', 'pandas.core.sparse', 'pandas.core.sparse.array', 'pandas._libs.sparse', 'pandas.io.formats.format', 'pandas.io.common', 'csv', '_csv', 'mmap', 'pandas.core.series', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._misc', 'pandas.plotting._style', 'pandas.plotting._compat', 'pandas.plotting._tools', 'pandas.plotting._core', 'pandas.plotting._converter', 'matplotlib', 'matplotlib.cbook', 'gzip', 'matplotlib.cbook.deprecation', 'matplotlib.cbook._backports', 'matplotlib.compat', 'matplotlib.compat.subprocess', 'matplotlib.rcsetup', 'matplotlib.testing', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'six.moves.urllib', 'six.moves.urllib.request', 'matplotlib._version']\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x121358d08>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x1213610d0>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x121361158>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x121579c80>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AccumulateNV2 (<function _accumulate_n_grad at 0x12157e0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcatLists (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListElementShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListLength (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBackBatch (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBack (<function _PushBackGrad at 0x12161de18>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPopBack (<function _PopBackGrad at 0x12161dea0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListStack (<function _TensorListStackGrad at 0x12161df28>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcat (<function _TensorListConcatGrad at 0x121627048>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSplit (<function _TensorListSplitGrad at 0x1216270d0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListFromTensor (<function _TensorListFromTensorGrad at 0x121627158>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGetItem (<function _TensorListGetItemGrad at 0x1216271e0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSetItem (<function _TensorListSetItemGrad at 0x121627268>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGather (<function _TensorListGatherGrad at 0x1216272f0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListScatter (<function _TensorListScatterGrad at 0x121627378>) in gradient.\n",
      "tensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <function CondContext.to_proto at 0x1216329d8>, <function CondContext.from_proto at 0x121632a60>)) in proto functions.\n",
      "tensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <function WhileContext.to_proto at 0x1216348c8>, <function WhileContext.from_proto at 0x1216349d8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReadVariableOp (<function _ReadGrad at 0x1216aaae8>) in gradient.\n",
      "tensorflow: Level 1: Registering ResourceGather (<function _GatherGrad at 0x1216ab598>) in gradient.\n",
      "tensorflow: Level 1: Registering variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering trainable_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering moving_average_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering local_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering model_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering global_step ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1216ab620>, <function _from_proto_fn at 0x1216ab6a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering VarIsInitializedOp (None) in gradient.\n",
      "tensorflow: Level 1: Registering VariableShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomStandardNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParameterizedTruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering TruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomUniform (None) in gradient.\n",
      "tensorflow: Level 1: Registering Multinomial (None) in gradient.\n",
      "tensorflow: Level 1: Registering EnsureShape (<function _ensure_shape_grad at 0x1217996a8>) in gradient.\n",
      "tensorflow: Level 1: Registering EagerPyFunc (<function _EagerPyFuncGrad at 0x1217a4378>) in gradient.\n",
      "tensorflow: Level 1: Registering PyFunc (None) in gradient.\n",
      "tensorflow: Level 1: Registering PyFuncStateless (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRead (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReadUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumRecordsProduced (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumWorkUnitsCompleted (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderSerializeState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRestoreState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReset (None) in gradient.\n",
      "tensorflow: Level 1: Registering WholeFileReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TextLineReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering FixedLengthRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TFRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering LMDBReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering RegexReplace (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucket (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketFast (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketStrong (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReduceJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringSplit (None) in gradient.\n",
      "tensorflow: Level 1: Registering AsString (None) in gradient.\n",
      "tensorflow: Level 1: Registering EncodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering savers ((<class 'tensorflow.core.protobuf.saver_pb2.SaverDef'>, <function Saver.to_proto at 0x121bee8c8>, <function Saver.from_proto at 0x121bee950>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReduceDataset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D,flops (<function _calc_conv_flops at 0x121d0ae18>) in statistical functions.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative,flops (<function _calc_depthwise_conv_flops at 0x121d0aea0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering BiasAdd,flops (<function _calc_bias_add_flops at 0x121d0af28>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Dilation2D,flops (<function _calc_dilation2d_flops at 0x121d10ae8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput (<function _Conv2DBackpropInputGrad at 0x121d10d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter (<function _Conv2DBackpropFilterGrad at 0x121d22048>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3D (<function _Conv3DGrad at 0x121d220d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropInputV2 (<function _Conv3DBackpropInputGrad at 0x121d22158>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropFilterV2 (<function _Conv3DBackpropFilterGrad at 0x121d221e0>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3D (<function _AvgPool3DGrad at 0x121d22268>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3DGrad (<function _AvgPool3DGradGrad at 0x121d222f0>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3D (<function _MaxPool3DGrad at 0x121d22378>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGrad (<function _MaxPool3DGradGrad at 0x121d22400>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGradGrad (<function _MaxPool3DGradGradGrad at 0x121d22488>) in gradient.\n",
      "tensorflow: Level 1: Registering Softmax (<function _SoftmaxGrad at 0x121d22510>) in gradient.\n",
      "tensorflow: Level 1: Registering LogSoftmax (<function _LogSoftmaxGrad at 0x121d22598>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAdd (<function _BiasAddGrad at 0x121d22620>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddGrad (<function _BiasAddGradGrad at 0x121d226a8>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddV1 (<function _BiasAddGradV1 at 0x121d22730>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu (<function _ReluGrad at 0x121d227b8>) in gradient.\n",
      "tensorflow: Level 1: Registering EluGrad (<function _EluGradGrad at 0x121d22840>) in gradient.\n",
      "tensorflow: Level 1: Registering SeluGrad (<function _SeluGradGrad at 0x121d228c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6 (<function _Relu6Grad at 0x121d22950>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6Grad (<function _Relu6GradGrad at 0x121d229d8>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyRelu (<function _LeakyReluGrad at 0x121d22a60>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyReluGrad (<function _LeakyReluGradGrad at 0x121d22ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Elu (<function _EluGrad at 0x121d22b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Selu (<function _SeluGrad at 0x121d22c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Softplus (<function _SoftplusGrad at 0x121d22d08>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftplusGrad (<function _SoftplusGradGrad at 0x121d22d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Softsign (<function _SoftsignGrad at 0x121d22e18>) in gradient.\n",
      "tensorflow: Level 1: Registering ReluGrad (<function _ReluGradGrad at 0x121d22ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftmaxCrossEntropyWithLogits (<function _SoftmaxCrossEntropyWithLogitsGrad at 0x121d27048>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmaxCrossEntropyWithLogits (<function _SparseSoftmaxCrossEntropyWithLogitsGrad at 0x121d270d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D (<function _Conv2DGrad at 0x121d27158>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative (<function _DepthwiseConv2dNativeGrad at 0x121d271e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Dilation2D (<function _Dilation2DGrad at 0x121d27268>) in gradient.\n",
      "tensorflow: Level 1: Registering LRN (<function _LRNGrad at 0x121d272f0>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool (<function _AvgPoolGrad at 0x121d27400>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPoolGrad (<function _AvgPoolGradGrad at 0x121d27488>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool (<function _MaxPoolGrad at 0x121d27510>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolV2 (<function _MaxPoolGradV2 at 0x121d27598>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolWithArgmax (<function _MaxPoolGradWithArgmax at 0x121d27620>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGrad (<function _MaxPoolGradGrad at 0x121d276a8>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradV2 (<function _MaxPoolGradGradV2 at 0x121d27730>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradGrad (<function _MaxPoolGradGradGrad at 0x121d277b8>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalMaxPool (<function _FractionalMaxPoolGrad at 0x121d27840>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalAvgPool (<function _FractionalAvgPoolGrad at 0x121d278c8>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchNormWithGlobalNormalization (<function _BatchNormWithGlobalNormalizationGrad at 0x121d27950>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNorm (<function _FusedBatchNormGrad at 0x121d27a60>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormV2 (<function _FusedBatchNormV2Grad at 0x121d27ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGrad (<function _FusedBatchNormGradGrad at 0x121d27bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGradV2 (<function _FusedBatchNormGradGradV2 at 0x121d27c80>) in gradient.\n",
      "tensorflow: Level 1: Registering L2Loss (<function _L2LossGrad at 0x121d27d08>) in gradient.\n",
      "tensorflow: Level 1: Registering TopKV2 (<function _TopKGrad at 0x121d27d90>) in gradient.\n",
      "tensorflow: Level 1: Registering TopK (<function _TopKGrad at 0x121d27d90>) in gradient.\n",
      "tensorflow: Level 1: Registering NthElement (<function _NthElementGrad at 0x121d27e18>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCLoss (<function _CTCLossGrad at 0x121d27ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCGreedyDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering CTCBeamSearchDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicPartition (<function _DynamicPartitionGrads at 0x121d34158>) in gradient.\n",
      "tensorflow: Level 1: Registering ParallelDynamicStitch (<function _DynamicStitchGrads at 0x121d34730>) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicStitch (<function _DynamicStitchGrads at 0x121d34730>) in gradient.\n",
      "tensorflow: Level 1: Registering Queue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering Stack (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPush (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPop (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandle (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandleV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering DeleteSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SetSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToDenseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering NcclAllReduce (<function _all_sum_grad at 0x121db8f28>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclReduce (<function _reduce_sum_grad at 0x121ddb268>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclBroadcast (<function _broadcast_grad at 0x121ddb378>) in gradient.\n",
      "tensorflow: Level 1: Registering Pack (<function _PackGrad at 0x121e3b730>) in gradient.\n",
      "tensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x121e3ba60>) in gradient.\n",
      "tensorflow: Level 1: Registering Concat (<function _ConcatGrad at 0x121e3bb70>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatV2 (<function _ConcatGradV2 at 0x121e3bbf8>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatOffset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Slice (<function _SliceGrad at 0x121e3bc80>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSlice (<function _StridedSliceGrad at 0x121e3bd08>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSliceGrad (<function _StridedSliceGradGrad at 0x121e3bd90>) in gradient.\n",
      "tensorflow: Level 1: Registering Split (<function _SplitGrad at 0x121e3be18>) in gradient.\n",
      "tensorflow: Level 1: Registering SplitV (<function _SplitVGrad at 0x121e3bea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Const (None) in gradient.\n",
      "tensorflow: Level 1: Registering Diag (<function _DiagGrad at 0x121e3bf28>) in gradient.\n",
      "tensorflow: Level 1: Registering DiagPart (<function _DiagPartGrad at 0x121e5c048>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiag (<function _MatrixDiagGrad at 0x121e5c0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiagPart (<function _MatrixDiagPartGrad at 0x121e5c158>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSetDiag (<function _MatrixSetDiagGrad at 0x121e5c1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixBandPart (<function _MatrixBandPartGrad at 0x121e5c268>) in gradient.\n",
      "tensorflow: Level 1: Registering EditDistance (None) in gradient.\n",
      "tensorflow: Level 1: Registering Fill (<function _FillGrad at 0x121e5c2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering ZerosLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering OnesLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering PreventGradient (<function _PreventGradientGrad at 0x121e5c378>) in gradient.\n",
      "tensorflow: Level 1: Registering Gather (<function _GatherGrad at 0x121e5c400>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherV2 (<function _GatherV2Grad at 0x121e5c488>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherNd (<function _GatherNdGrad at 0x121e5c510>) in gradient.\n",
      "tensorflow: Level 1: Registering CheckNumerics (<function _CheckNumericsGrad at 0x121e5c598>) in gradient.\n",
      "tensorflow: Level 1: Registering Identity (<function _IdGrad at 0x121e5c620>) in gradient.\n",
      "tensorflow: Level 1: Registering PlaceholderWithDefault (<function _IdGrad at 0x121e5c620>) in gradient.\n",
      "tensorflow: Level 1: Registering RefIdentity (<function _RefIdGrad at 0x121e5c6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityN (<function _IdNGrad at 0x121e5c730>) in gradient.\n",
      "tensorflow: Level 1: Registering StopGradient (None) in gradient.\n",
      "tensorflow: Level 1: Registering Reshape (<function _ReshapeGrad at 0x121e5c7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering InvertPermutation (None) in gradient.\n",
      "tensorflow: Level 1: Registering ExpandDims (<function _ExpandDimsGrad at 0x121e5c8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Squeeze (<function _SqueezeGrad at 0x121e5c950>) in gradient.\n",
      "tensorflow: Level 1: Registering Transpose (<function _TransposeGrad at 0x121e5c9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering ConjugateTranspose (<function _ConjugateTransposeGrad at 0x121e5ca60>) in gradient.\n",
      "tensorflow: Level 1: Registering Shape (None) in gradient.\n",
      "tensorflow: Level 1: Registering ShapeN (None) in gradient.\n",
      "tensorflow: Level 1: Registering Rank (None) in gradient.\n",
      "tensorflow: Level 1: Registering Size (None) in gradient.\n",
      "tensorflow: Level 1: Registering Tile (<function _TileGrad at 0x121e5cae8>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastGradientArgs (None) in gradient.\n",
      "tensorflow: Level 1: Registering Pad (<function _PadGrad at 0x121e5cb70>) in gradient.\n",
      "tensorflow: Level 1: Registering PadV2 (<function _PadGrad at 0x121e5cb70>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseSequence (<function _ReverseSequenceGrad at 0x121e5cc80>) in gradient.\n",
      "tensorflow: Level 1: Registering Reverse (<function _ReverseGrad at 0x121e5cd08>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseV2 (<function _ReverseV2Grad at 0x121e5cd90>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatch (<function _SpaceToBatchGrad at 0x121e5ce18>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatchND (<function _SpaceToBatchNDGrad at 0x121e5cea0>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpace (<function _BatchToSpaceGrad at 0x121e5cf28>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpaceND (<function _BatchToSpaceNDGrad at 0x121e65048>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToDepth (<function _SpaceToDepthGrad at 0x121e650d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthToSpace (<function _DepthToSpaceGrad at 0x121e65158>) in gradient.\n",
      "tensorflow: Level 1: Registering OneHot (None) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPad (<function _MirrorPadGrad at 0x121e651e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPadGrad (<function _MirrorPadGradGrad at 0x121e65268>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantize (<function _QuantizeAndDequantizeGrad at 0x121e652f0>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV2 (<function _QuantizeAndDequantizeV2Grad at 0x121e65378>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV3 (<function _QuantizeAndDequantizeV3Grad at 0x121e65400>) in gradient.\n",
      "tensorflow: Level 1: Registering ExtractImagePatches (<function _ExtractImagePatchesGrad at 0x121e65488>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNd (<function _ScatterNdGrad at 0x121e65510>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterUpdate (<function _TensorScatterUpdateGrad at 0x121e65598>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterAdd (<function _TensorScatterAddGrad at 0x121e65620>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterSub (<function _TensorScatterSubGrad at 0x121e656a8>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdNonAliasingAdd (<function _ScatterNdNonAliasingAddGrad at 0x121e65730>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastTo (<function _BroadcastToGrad at 0x121e657b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Switch (<function _SwitchGrad at 0x121e65840>) in gradient.\n",
      "tensorflow: Level 1: Registering RefSwitch (<function _SwitchGrad at 0x121e65840>) in gradient.\n",
      "tensorflow: Level 1: Registering Merge (<function _MergeGrad at 0x121e658c8>) in gradient.\n",
      "tensorflow: Level 1: Registering RefMerge (<function _RefMergeGrad at 0x121e65950>) in gradient.\n",
      "tensorflow: Level 1: Registering Exit (<function _ExitGrad at 0x121e659d8>) in gradient.\n",
      "tensorflow: Level 1: Registering RefExit (<function _ExitGrad at 0x121e659d8>) in gradient.\n",
      "tensorflow: Level 1: Registering NextIteration (<function _NextIterationGrad at 0x121e65a60>) in gradient.\n",
      "tensorflow: Level 1: Registering RefNextIteration (<function _RefNextIterationGrad at 0x121e65ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Enter (<function _EnterGrad at 0x121e65b70>) in gradient.\n",
      "tensorflow: Level 1: Registering RefEnter (<function _RefEnterGrad at 0x121e65bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering LoopCond (<function _LoopCondGrad at 0x121e65c80>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeNearestNeighbor (<function _ResizeNearestNeighborGrad at 0x121e65d08>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBilinear (<function _ResizeBilinearGrad at 0x121e85d90>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBicubic (<function _ResizeBicubicGrad at 0x121e85e18>) in gradient.\n",
      "tensorflow: Level 1: Registering CropAndResize (<function _CropAndResizeGrad at 0x121e85ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixInverse (<function _MatrixInverseGrad at 0x121e85f28>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDeterminant (<function _MatrixDeterminantGrad at 0x121e97378>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSquareRoot (<function _MatrixSquareRootGrad at 0x121e97ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering LogMatrixDeterminant (<function _LogMatrixDeterminantGrad at 0x121e97f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Cholesky (<function _CholeskyGrad at 0x121eb0048>) in gradient.\n",
      "tensorflow: Level 1: Registering Qr (<function _QrGrad at 0x121eb00d0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolve (<function _MatrixSolveGrad at 0x121eb01e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolveLs (<function _MatrixSolveLsGrad at 0x121eb0268>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixTriangularSolve (<function _MatrixTriangularSolveGrad at 0x121eb02f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SelfAdjointEigV2 (<function _SelfAdjointEigV2Grad at 0x121eb0378>) in gradient.\n",
      "tensorflow: Level 1: Registering Svd (<function _SvdGrad at 0x121eb0400>) in gradient.\n",
      "tensorflow: Level 1: Registering Print (<function _PrintGrad at 0x121eb07b8>) in gradient.\n",
      "tensorflow: Level 1: Registering HistogramSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ImageSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MergeSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScalarSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering Timestamp (None) in gradient.\n",
      "tensorflow: Level 1: Registering Roll (<function _RollGrad at 0x121eb0ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMax (<function _ArgMaxGrad at 0x121eb5bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMin (<function _ArgMinGrad at 0x121eb5c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Sum (<function _SumGrad at 0x121eb5d08>) in gradient.\n",
      "tensorflow: Level 1: Registering Max (<function _MaxGrad at 0x121eb5ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Min (<function _MinGrad at 0x121ed1048>) in gradient.\n",
      "tensorflow: Level 1: Registering Mean (<function _MeanGrad at 0x121ed1158>) in gradient.\n",
      "tensorflow: Level 1: Registering Prod (<function _ProdGrad at 0x121ed11e0>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentSum (<function _SegmentSumGrad at 0x121ed1268>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMean (<function _SegmentMeanGrad at 0x121ed12f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSum (<function _SparseSegmentSumGrad at 0x121ed1378>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSumWithNumSegments (<function _SparseSegmentSumWithNumSegmentsGrad at 0x121ed1400>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMean (<function _SparseSegmentMeanGrad at 0x121ed1488>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMeanWithNumSegments (<function _SparseSegmentMeanWithNumSegmentsGrad at 0x121ed1510>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtN (<function _SparseSegmentSqrtNGrad at 0x121ed1598>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtNWithNumSegments (<function _SparseSegmentSqrtNWithNumSegmentsGrad at 0x121ed1620>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMin (<function _SegmentMinGrad at 0x121ed1730>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMax (<function _SegmentMaxGrad at 0x121ed17b8>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentSum (<function _UnsortedSegmentSumGrad at 0x121ed1950>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMax (<function _UnsortedSegmentMaxGrad at 0x121ed19d8>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMin (<function _UnsortedSegmentMinGrad at 0x121ed1a60>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentProd (<function _UnsortedSegmentProdGrad at 0x121ed1ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Abs (<function _AbsGrad at 0x121ed1b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Neg (<function _NegGrad at 0x121ed1c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Inv (<function _InvGrad at 0x121ed1d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Reciprocal (<function _ReciprocalGrad at 0x121ed1ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering InvGrad (<function _InvGradGrad at 0x121ed1f28>) in gradient.\n",
      "tensorflow: Level 1: Registering ReciprocalGrad (<function _ReciprocalGradGrad at 0x121ed5048>) in gradient.\n",
      "tensorflow: Level 1: Registering Square (<function _SquareGrad at 0x121ed50d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sqrt (<function _SqrtGrad at 0x121ed5158>) in gradient.\n",
      "tensorflow: Level 1: Registering SqrtGrad (<function _SqrtGradGrad at 0x121ed51e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Rsqrt (<function _RsqrtGrad at 0x121ed5268>) in gradient.\n",
      "tensorflow: Level 1: Registering RsqrtGrad (<function _RsqrtGradGrad at 0x121ed52f0>) in gradient.\n",
      "tensorflow: Level 1: Registering Exp (<function _ExpGrad at 0x121ed5378>) in gradient.\n",
      "tensorflow: Level 1: Registering Expm1 (<function _Expm1Grad at 0x121ed5488>) in gradient.\n",
      "tensorflow: Level 1: Registering Log (<function _LogGrad at 0x121ed5510>) in gradient.\n",
      "tensorflow: Level 1: Registering Log1p (<function _Log1pGrad at 0x121ed5620>) in gradient.\n",
      "tensorflow: Level 1: Registering Xlogy (<function _XLogyGrad at 0x121ed56a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Xdivy (<function _XDivyGrad at 0x121ed5730>) in gradient.\n",
      "tensorflow: Level 1: Registering Sinh (<function _SinhGrad at 0x121ed57b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Cosh (<function _CoshGrad at 0x121ed5840>) in gradient.\n",
      "tensorflow: Level 1: Registering Tanh (<function _TanhGrad at 0x121ed58c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Asinh (<function _AsinhGrad at 0x121ed5950>) in gradient.\n",
      "tensorflow: Level 1: Registering Acosh (<function _AcoshGrad at 0x121ed59d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Atanh (<function _AtanhGrad at 0x121ed5a60>) in gradient.\n",
      "tensorflow: Level 1: Registering TanhGrad (<function _TanhGradGrad at 0x121ed5ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Erf (<function _ErfGrad at 0x121ed5b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Erfc (<function _ErfcGrad at 0x121ed5c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Lgamma (<function _LgammaGrad at 0x121ed5d08>) in gradient.\n",
      "tensorflow: Level 1: Registering Digamma (<function _DigammaGrad at 0x121ed5d90>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI0e (<function _BesselI0eGrad at 0x121ed5e18>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI1e (<function _BesselI1eGrad at 0x121ed5ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Igamma (<function _IgammaGrad at 0x121ed5f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Igammac (<function _IgammacGrad at 0x121ed9048>) in gradient.\n",
      "tensorflow: Level 1: Registering Betainc (<function _BetaincGrad at 0x121ed90d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Zeta (<function _ZetaGrad at 0x121ed9158>) in gradient.\n",
      "tensorflow: Level 1: Registering Polygamma (<function _PolygammaGrad at 0x121ed91e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sigmoid (<function _SigmoidGrad at 0x121ed9268>) in gradient.\n",
      "tensorflow: Level 1: Registering SigmoidGrad (<function _SigmoidGradGrad at 0x121ed92f0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sign (<function _SignGrad at 0x121ed9378>) in gradient.\n",
      "tensorflow: Level 1: Registering Sin (<function _SinGrad at 0x121ed9400>) in gradient.\n",
      "tensorflow: Level 1: Registering Cos (<function _CosGrad at 0x121ed9510>) in gradient.\n",
      "tensorflow: Level 1: Registering Tan (<function _TanGrad at 0x121ed9620>) in gradient.\n",
      "tensorflow: Level 1: Registering Asin (<function _AsinGrad at 0x121ed9730>) in gradient.\n",
      "tensorflow: Level 1: Registering Acos (<function _AcosGrad at 0x121ed97b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan (<function _AtanGrad at 0x121ed9840>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan2 (<function _Atan2Grad at 0x121ed98c8>) in gradient.\n",
      "tensorflow: Level 1: Registering AddN (<function _AddNGrad at 0x121ed9950>) in gradient.\n",
      "tensorflow: Level 1: Registering Add (<function _AddGrad at 0x121ed9a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Sub (<function _SubGrad at 0x121ed9b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Mul (<function _MulGrad at 0x121ed9c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Div (<function _DivGrad at 0x121ed9d90>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorDiv (<function _FloorDivGrad at 0x121ed9ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorMod (<function _FloorModGrad at 0x121ed9f28>) in gradient.\n",
      "tensorflow: Level 1: Registering TruncateDiv (<function _TruncateDivGrad at 0x121edc048>) in gradient.\n",
      "tensorflow: Level 1: Registering RealDiv (<function _RealDivGrad at 0x121edc0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DivNoNan (<function _DivNoNanGrad at 0x121edc158>) in gradient.\n",
      "tensorflow: Level 1: Registering Pow (<function _PowGrad at 0x121edc1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Maximum (<function _MaximumGrad at 0x121edc378>) in gradient.\n",
      "tensorflow: Level 1: Registering Minimum (<function _MinimumGrad at 0x121edc400>) in gradient.\n",
      "tensorflow: Level 1: Registering SquaredDifference (<function _SquaredDifferenceGrad at 0x121edc488>) in gradient.\n",
      "tensorflow: Level 1: Registering Less (None) in gradient.\n",
      "tensorflow: Level 1: Registering LessEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Greater (None) in gradient.\n",
      "tensorflow: Level 1: Registering GreaterEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Equal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ApproximateEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering NotEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalAnd (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalOr (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalNot (None) in gradient.\n",
      "tensorflow: Level 1: Registering Select (<function _SelectGrad at 0x121edc510>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul (<function _MatMulGrad at 0x121edc598>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseMatMul (<function _SparseMatMulGrad at 0x121edc620>) in gradient.\n",
      "tensorflow: Level 1: Registering Floor (<function _FloorGrad at 0x121edc6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Ceil (<function _CeilGrad at 0x121edc730>) in gradient.\n",
      "tensorflow: Level 1: Registering Round (<function _RoundGrad at 0x121edc7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Rint (<function _RintGrad at 0x121edc840>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchMatMul (<function _BatchMatMul at 0x121edc8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Range (None) in gradient.\n",
      "tensorflow: Level 1: Registering LinSpace (None) in gradient.\n",
      "tensorflow: Level 1: Registering Complex (<function _ComplexGrad at 0x121edc950>) in gradient.\n",
      "tensorflow: Level 1: Registering Real (<function _RealGrad at 0x121edc9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Imag (<function _ImagGrad at 0x121edca60>) in gradient.\n",
      "tensorflow: Level 1: Registering Angle (<function _AngleGrad at 0x121edcae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Conj (<function _ConjGrad at 0x121edcb70>) in gradient.\n",
      "tensorflow: Level 1: Registering ComplexAbs (<function _ComplexAbsGrad at 0x121edcbf8>) in gradient.\n",
      "tensorflow: Level 1: Registering Cast (<function _CastGrad at 0x121edcc80>) in gradient.\n",
      "tensorflow: Level 1: Registering Cross (<function _CrossGrad at 0x121edcd08>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumsum (<function _CumsumGrad at 0x121edcd90>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumprod (<function _CumprodGrad at 0x121edce18>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalFromValue (<function _OptionalFromValueGrad at 0x121edcea0>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalGetValue (<function _OptionalGetValueGrad at 0x121edcf28>) in gradient.\n",
      "tensorflow: Level 1: Registering RandomGamma (<function _RandomGammaGrad at 0x121ee10d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeRaw (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParseTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SerializeTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToNumber (None) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNN (<function _cudnn_rnn_backward at 0x12175e840>) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNNV2 (<function _cudnn_rnn_backward_v2 at 0x122061b70>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAddGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseConcat (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToDense (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReorder (<function _SparseReorderGrad at 0x122061bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAdd (<function _SparseAddGrad at 0x122061d90>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseAdd (<function _SparseTensorDenseAddGrad at 0x122061e18>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReduceSum (<function _SparseReduceSumGrad at 0x122061ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSlice (<function _SparseSliceGrad at 0x122061f28>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseMatMul (<function _SparseTensorDenseMatMulGrad at 0x12206c048>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseAdd (<function _SparseDenseCwiseAddGrad at 0x12206c0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseMul (<function _SparseDenseCwiseMulGrad at 0x12206c1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseDiv (<function _SparseDenseCwiseDivGrad at 0x12206c268>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmax (<function _SparseSoftmaxGrad at 0x12206c2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMaximum (<function _SparseSparseMaximumGrad at 0x12206c378>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMinimum (<function _SparseSparseMinimumGrad at 0x12206c400>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseFillEmptyRows (<function _SparseFillEmptyRowsGrad at 0x12206c488>) in gradient.\n",
      "tensorflow: Level 1: Registering Assign (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdUpdate (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArray (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySize (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradWithShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV3 (<function _TensorArrayReadGrad at 0x12206c730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV2 (<function _TensorArrayReadGrad at 0x12206c730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayRead (<function _TensorArrayReadGrad at 0x12206c730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV3 (<function _TensorArrayWriteGrad at 0x12206c7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV2 (<function _TensorArrayWriteGrad at 0x12206c7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWrite (<function _TensorArrayWriteGrad at 0x12206c7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV3 (<function _TensorArrayGatherGrad at 0x12206c840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV2 (<function _TensorArrayGatherGrad at 0x12206c840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGather (<function _TensorArrayGatherGrad at 0x12206c840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatterV3 (<function _TensorArrayScatterGrad at 0x12206c8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatterV2 (<function _TensorArrayScatterGrad at 0x12206c8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatter (<function _TensorArrayScatterGrad at 0x12206c8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV3 (<function _TensorArrayConcatGrad at 0x12206c950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV2 (<function _TensorArrayConcatGrad at 0x12206c950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcat (<function _TensorArrayConcatGrad at 0x12206c950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplitV3 (<function _TensorArraySplitGrad at 0x12206c9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplitV2 (<function _TensorArraySplitGrad at 0x12206c9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplit (<function _TensorArraySplitGrad at 0x12206c9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableFind (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableFindV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableInsert (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableInsertV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableSizeV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering HashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering HashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFile (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFileV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableDenseHashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableDenseHashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensors (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensorsV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering RaggedTensorToSparse (<function _ragged_tensor_to_sparse_gradient at 0x1220f9400>) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessMultinomial (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomUniform (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomUniformInt (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessTruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomCrop (None) in gradient.\n",
      "tensorflow: Level 1: Registering RGBToHSV (None) in gradient.\n",
      "tensorflow: Level 1: Registering HSVToRGB (None) in gradient.\n",
      "tensorflow: Level 1: Registering DrawBoundingBoxes (None) in gradient.\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBox (None) in gradient.\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBoxV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering ExtractGlimpse (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppression (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionWithOverlaps (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseAnd (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseOr (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseXor (None) in gradient.\n",
      "tensorflow: Level 1: Registering Invert (None) in gradient.\n",
      "tensorflow: Level 1: Registering PopulationCount (None) in gradient.\n",
      "tensorflow: Level 1: Registering LeftShift (None) in gradient.\n",
      "tensorflow: Level 1: Registering RightShift (None) in gradient.\n",
      "tensorflow: Level 1: Registering FFT (<function _fft_grad at 0x12e9a5400>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT (<function _ifft_grad at 0x12e9a5510>) in gradient.\n",
      "tensorflow: Level 1: Registering FFT2D (<function _fft2d_grad at 0x12e9a5598>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT2D (<function _ifft2d_grad at 0x12e9a5620>) in gradient.\n",
      "tensorflow: Level 1: Registering FFT3D (<function _fft3d_grad at 0x12e9a56a8>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT3D (<function _ifft3d_grad at 0x12e9a5730>) in gradient.\n",
      "tensorflow: Level 1: Registering RFFT (<function _rfft_grad_helper.<locals>._grad at 0x12e9a58c8>) in gradient.\n",
      "tensorflow: Level 1: Registering IRFFT (<function _irfft_grad_helper.<locals>._grad at 0x12e9a5950>) in gradient.\n",
      "tensorflow: Level 1: Registering RFFT2D (<function _rfft_grad_helper.<locals>._grad at 0x12e9a59d8>) in gradient.\n",
      "tensorflow: Level 1: Registering IRFFT2D (<function _irfft_grad_helper.<locals>._grad at 0x12e9a5a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Reciprocal,flops (<function _reciprocal_flops at 0x12e9f21e0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Square,flops (<function _square_flops at 0x12e9f2268>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Rsqrt,flops (<function _rsqrt_flops at 0x12e9f22f0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Log,flops (<function _log_flops at 0x12e9f2378>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Neg,flops (<function _neg_flops at 0x12e9f2400>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AssignSub,flops (<function _assign_sub_flops at 0x12e9f2488>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AssignAdd,flops (<function _assign_add_flops at 0x12e9f2510>) in statistical functions.\n",
      "tensorflow: Level 1: Registering L2Loss,flops (<function _l2_loss_flops at 0x12e9f2598>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Softmax,flops (<function _softmax_flops at 0x12e9f2620>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Add,flops (<function _add_flops at 0x12e9f2730>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Sub,flops (<function _sub_flops at 0x12e9f27b8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Mul,flops (<function _mul_flops at 0x12e9f2840>) in statistical functions.\n",
      "tensorflow: Level 1: Registering RealDiv,flops (<function _real_div_flops at 0x12e9f28c8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Maximum,flops (<function _maximum_flops at 0x12e9f2950>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Minimum,flops (<function _minimum_flops at 0x12e9f29d8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Pow,flops (<function _pow_flops at 0x12e9f2a60>) in statistical functions.\n",
      "tensorflow: Level 1: Registering RsqrtGrad,flops (<function _rsqrt_grad_flops at 0x12e9f2ae8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering GreaterEqual,flops (<function _greater_equal_flops at 0x12e9f2b70>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Greater,flops (<function _greater_flops at 0x12e9f2bf8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering LessEqual,flops (<function _less_equal_flops at 0x12e9f2c80>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Less,flops (<function _less_flops at 0x12e9f2d08>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Equal,flops (<function _equal_flops at 0x12e9f2d90>) in statistical functions.\n",
      "tensorflow: Level 1: Registering NotEqual,flops (<function _not_equal_flops at 0x12e9f2e18>) in statistical functions.\n",
      "tensorflow: Level 1: Registering SquaredDifference,flops (<function _squared_difference_flops at 0x12e9f2ea0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Mean,flops (<function _mean_flops at 0x12e9fb048>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Sum,flops (<function _sum_flops at 0x12e9fb0d0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering ArgMax,flops (<function _arg_max_flops at 0x12e9fb158>) in statistical functions.\n",
      "tensorflow: Level 1: Registering ArgMin,flops (<function _arg_min_flops at 0x12e9fb1e0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering BiasAddGrad,flops (<function _bias_add_grad_flops at 0x12e9fb268>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AvgPool,flops (<function _avg_pool_flops at 0x12e9fb400>) in statistical functions.\n",
      "tensorflow: Level 1: Registering MaxPool,flops (<function _max_pool_flops at 0x12e9fb488>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AvgPoolGrad,flops (<function _avg_pool_grad_flops at 0x12e9fb510>) in statistical functions.\n",
      "tensorflow: Level 1: Registering MaxPoolGrad,flops (<function _max_pool_grad_flops at 0x12e9fb598>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput,flops (<function _conv_2d_backprop_input_flops at 0x12e9fb620>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter,flops (<function _conv_2d_backprop_filter_flops at 0x12e9fb6a8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AddN,flops (<function _add_n_flops at 0x12e9fb730>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Fact (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x12119cea0>) in default shape functions.\n",
      "tensorflow: Level 1: Registering SdcaFprint (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaOptimizer (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaOptimizerV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaShrinkL1 (None) in gradient.\n",
      "tensorflow: Level 1: Registering queue_runners ((<class 'tensorflow.core.protobuf.queue_runner_pb2.QueueRunnerDef'>, <function QueueRunner.to_proto at 0x12ea74f28>, <function QueueRunner.from_proto at 0x12ea82048>)) in proto functions.\n",
      "tensorflow: Level 1: Registering GenerateVocabRemapping (None) in gradient.\n",
      "tensorflow: Level 1: Registering LoadAndRemapMatrix (None) in gradient.\n",
      "--------------------- >> end captured logging << ---------------------\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "# use ! to run shell commands in notebook\n",
    "! nosetests tests/test_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid long debug messages when running in the shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nosetests tests/test_environment.py --nologcapture --nocapture\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/rock-lyrics-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a structured representation of your data. You can preview a dataframe using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Era</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000s</td>\n",
       "      <td>Don't tell me what to think 'Cause I don't car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000s</td>\n",
       "      <td>Whenever the lights go down That's when she co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000s</td>\n",
       "      <td>You say this will be alright Just put my faith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000s</td>\n",
       "      <td>There's one who takes it all And there's one w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000s</td>\n",
       "      <td>So far away from knowing where I am going I am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Era                                             Lyrics\n",
       "0  2000s  Don't tell me what to think 'Cause I don't car...\n",
       "1  2000s  Whenever the lights go down That's when she co...\n",
       "2  2000s  You say this will be alright Just put my faith...\n",
       "3  2000s  There's one who takes it all And there's one w...\n",
       "4  2000s  So far away from knowing where I am going I am..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bags of words\n",
    "\n",
    "Your first task is to convert the text to a bag-of-words representation. For this data, a lot of the preprocessing is already done: the text is lower-cased, and punctuation is removed. You need only create a `counter` for each instance.\n",
    "\n",
    "- **Deliverable 1.1**: Complete the function `snlp.preproc.bag_of_words`. \n",
    "- **Test**: `nosetests tests/test_preproc.py:test_d1_1_bow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlp import preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block to update the notebook as you change the preproc library\n",
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F\n",
      "======================================================================\n",
      "FAIL: test_environment.test_library_versions\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/davidmortensen/anaconda3/lib/python3.7/site-packages/nose/case.py\", line 197, in runTest\n",
      "    self.test(*self.arg)\n",
      "  File \"/Users/davidmortensen/2ndyearproject/Milestone1/tests/test_environment.py\", line 30, in test_library_versions\n",
      "    ok_(LooseVersion(sys.version) < LooseVersion(max_python)) # make sure not to use py3.7\n",
      "AssertionError: None\n",
      "-------------------- >> begin captured logging << --------------------\n",
      "matplotlib: DEBUG: $HOME=/Users/davidmortensen\n",
      "matplotlib: DEBUG: matplotlib data path /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data\n",
      "matplotlib: DEBUG: loaded rc file /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc\n",
      "matplotlib: DEBUG: matplotlib version 2.2.3\n",
      "matplotlib: DEBUG: interactive is False\n",
      "matplotlib: DEBUG: platform is darwin\n",
      "matplotlib: DEBUG: loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', 'posixpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', '_bootlocale', '_locale', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'sphinxcontrib', 'zope', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'nose', 'nose.core', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 'token', 'weakref', '_weakrefset', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'difflib', 'pprint', 'unittest.suite', 'unittest.loader', 'fnmatch', 'unittest.main', 'argparse', 'gettext', 'locale', 'unittest.runner', 'unittest.signals', 'signal', 'nose.config', 'optparse', 'textwrap', 'errno', 'configparser', 'nose.util', 'inspect', 'dis', 'opcode', '_opcode', 'nose.pyversion', 'nose.plugins', 'nose.plugins.base', 'nose.plugins.manager', 'nose.failure', 'pickle', 'struct', '_struct', '_compat_pickle', '_pickle', 'pkg_resources', '__future__', 'zipfile', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'binascii', 'pkgutil', 'platform', 'subprocess', '_posixsubprocess', 'select', 'selectors', 'math', 'plistlib', 'datetime', '_datetime', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'base64', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'random', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'socket', '_socket', 'urllib', 'urllib.parse', 'email._parseaddr', 'calendar', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources.extern.six', 'pkg_resources._vendor.six', 'pkg_resources.extern.six.moves', 'pkg_resources._vendor.six.moves', 'pkg_resources.py31compat', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging._compat', 'pkg_resources.extern.packaging.requirements', 'copy', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.six.moves.urllib', 'pkg_resources.extern.packaging.markers', 'sysconfig', '_osx_support', '_sysconfigdata_m_darwin_darwin', 'nose.plugins.plugintest', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'nose.loader', 'nose.case', 'nose.importer', 'imp', 'nose.selector', 'nose.suite', 'nose.proxy', 'nose.result', 'nose.exc', 'nose.plugins.skip', 'nose.plugins.errorclass', 'nose.plugins.deprecated', 'nose.tools', 'nose.tools.nontrivial', 'nose.tools.trivial', 'nose.plugins.builtin', 'nose.plugins.attrib', 'nose.plugins.capture', 'nose.plugins.logcapture', 'nose.plugins.cover', 'nose.plugins.debug', 'pdb', 'cmd', 'bdb', 'code', 'codeop', 'glob', 'nose.plugins.doctests', 'doctest', 'nose.plugins.isolate', 'nose.plugins.failuredetail', 'nose.inspector', 'nose.plugins.prof', 'nose.plugins.testid', 'nose.plugins.multiprocess', 'queue', '_queue', 'nose.plugins.xunit', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'xml.sax.saxutils', 'urllib.request', 'http', 'http.client', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'ssl', '_ssl', 'urllib.error', 'urllib.response', '_scproxy', 'nose.plugins.allmodules', 'nose.plugins.collect', 'test_environment', 'distutils', 'distutils.version', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._import_tools', 'numpy.add_newdocs', 'numpy.lib', 'numpy.lib.info', 'numpy.lib.type_check', 'numpy.core', 'numpy.core.info', 'numpy.core.multiarray', 'numpy.core.umath', 'numpy.core._internal', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'ntpath', 'ctypes', '_ctypes', 'ctypes._endian', 'numpy.core.numerictypes', 'numbers', 'numpy.core.numeric', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.shape_base', 'numpy.core.einsumfunc', 'numpy.testing', 'numpy.testing._private', 'numpy.testing._private.utils', 'gc', 'numpy.lib.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'numpy.testing._private.pytesttester', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.lib.function_base', 'numpy.lib.twodim_base', 'numpy.lib.histograms', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'ast', '_ast', 'numpy.linalg', 'numpy.linalg.info', 'numpy.linalg.linalg', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.stride_tricks', 'numpy.lib.mixins', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.scimath', 'numpy.lib.polynomial', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.core._multiarray_tests', 'numpy._distributor_init', 'numpy.fft', 'numpy.fft.info', 'numpy.fft.fftpack', 'numpy.fft.fftpack_lite', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random.info', 'cython_runtime', 'mtrand', 'numpy.random.mtrand', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'unicodedata', 'pandas.compat.chainmap', 'dateutil.parser', 'dateutil.parser._parser', 'six', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.parser.isoparser', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslib', 'pandas._libs.tslibs', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.np_datetime', '_cython_0_28_4', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.timestamps', 'pandas._libs.tslibs.fields', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.lib', 'pandas.core', 'pandas.core.config_init', 'pandas.core.config', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.printing', 'pandas.core.dtypes', 'pandas.core.dtypes.inference', 'pandas.io.formats.console', 'pandas.io.formats.terminal', 'pandas.core.api', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.common', 'pandas._libs.algos', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.missing', 'pandas.core.common', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.util._validators', 'pandas.core.arrays.categorical', 'pandas.core.accessor', 'pandas.core.base', 'pandas.core.nanops', 'bottleneck', 'bottleneck.reduce', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.move', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck.version', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'pandas.core.missing', 'pandas.core.groupby', 'pandas.core.groupby.groupby', 'pandas.core.index', 'pandas.core.indexes', 'pandas.core.indexes.api', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.frequencies', 'pandas._libs.tslibs.resolution', 'pandas.tseries', 'pandas.tseries.offsets', 'pandas.core.tools', 'pandas.core.tools.datetimes', 'dateutil.easter', 'pandas._libs.tslibs.offsets', 'pandas.tseries.frequencies', 'pandas._libs.join', 'pandas.core.ops', 'pandas._libs.ops', 'pandas.core.indexes.frozen', 'pandas.core.dtypes.concat', 'pandas.core.sorting', 'pandas.core.strings', 'pandas.core.indexes.category', 'pandas.core.indexes.multi', 'pandas.core.indexes.interval', 'pandas._libs.interval', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.numeric', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.range', 'pandas.core.indexes.period', 'pandas.core.frame', 'pandas.core.generic', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.internals', 'pandas._libs.internals', 'pandas.core.sparse', 'pandas.core.sparse.array', 'pandas._libs.sparse', 'pandas.io.formats.format', 'pandas.io.common', 'csv', '_csv', 'mmap', 'pandas.core.series', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._misc', 'pandas.plotting._style', 'pandas.plotting._compat', 'pandas.plotting._tools', 'pandas.plotting._core', 'pandas.plotting._converter', 'matplotlib', 'matplotlib.cbook', 'gzip', 'matplotlib.cbook.deprecation', 'matplotlib.cbook._backports', 'matplotlib.compat', 'matplotlib.compat.subprocess', 'matplotlib.rcsetup', 'matplotlib.testing', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'six.moves.urllib', 'six.moves.urllib.request', 'matplotlib._version']\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x125b00d08>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x125b090d0>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x125b09158>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x125d20c80>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AccumulateNV2 (<function _accumulate_n_grad at 0x125d260d0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcatLists (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListElementShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListLength (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBackBatch (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBack (<function _PushBackGrad at 0x125dc5e18>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPopBack (<function _PopBackGrad at 0x125dc5ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListStack (<function _TensorListStackGrad at 0x125dc5f28>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcat (<function _TensorListConcatGrad at 0x125dcf048>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSplit (<function _TensorListSplitGrad at 0x125dcf0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListFromTensor (<function _TensorListFromTensorGrad at 0x125dcf158>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGetItem (<function _TensorListGetItemGrad at 0x125dcf1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSetItem (<function _TensorListSetItemGrad at 0x125dcf268>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGather (<function _TensorListGatherGrad at 0x125dcf2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListScatter (<function _TensorListScatterGrad at 0x125dcf378>) in gradient.\n",
      "tensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <function CondContext.to_proto at 0x125ddb9d8>, <function CondContext.from_proto at 0x125ddba60>)) in proto functions.\n",
      "tensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <function WhileContext.to_proto at 0x125ddd8c8>, <function WhileContext.from_proto at 0x125ddd9d8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReadVariableOp (<function _ReadGrad at 0x125e54ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering ResourceGather (<function _GatherGrad at 0x125e55598>) in gradient.\n",
      "tensorflow: Level 1: Registering variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering trainable_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering moving_average_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering local_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering model_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering global_step ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x125e55620>, <function _from_proto_fn at 0x125e556a8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering VarIsInitializedOp (None) in gradient.\n",
      "tensorflow: Level 1: Registering VariableShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomStandardNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParameterizedTruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering TruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomUniform (None) in gradient.\n",
      "tensorflow: Level 1: Registering Multinomial (None) in gradient.\n",
      "tensorflow: Level 1: Registering EnsureShape (<function _ensure_shape_grad at 0x125f426a8>) in gradient.\n",
      "tensorflow: Level 1: Registering EagerPyFunc (<function _EagerPyFuncGrad at 0x125f4c378>) in gradient.\n",
      "tensorflow: Level 1: Registering PyFunc (None) in gradient.\n",
      "tensorflow: Level 1: Registering PyFuncStateless (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRead (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReadUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumRecordsProduced (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumWorkUnitsCompleted (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderSerializeState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRestoreState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReset (None) in gradient.\n",
      "tensorflow: Level 1: Registering WholeFileReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TextLineReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering FixedLengthRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TFRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering LMDBReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering RegexReplace (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucket (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketFast (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketStrong (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReduceJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringSplit (None) in gradient.\n",
      "tensorflow: Level 1: Registering AsString (None) in gradient.\n",
      "tensorflow: Level 1: Registering EncodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering savers ((<class 'tensorflow.core.protobuf.saver_pb2.SaverDef'>, <function Saver.to_proto at 0x1263968c8>, <function Saver.from_proto at 0x126396950>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReduceDataset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D,flops (<function _calc_conv_flops at 0x1264b2e18>) in statistical functions.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative,flops (<function _calc_depthwise_conv_flops at 0x1264b2ea0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering BiasAdd,flops (<function _calc_bias_add_flops at 0x1264b2f28>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Dilation2D,flops (<function _calc_dilation2d_flops at 0x1264b9ae8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput (<function _Conv2DBackpropInputGrad at 0x1264b9d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter (<function _Conv2DBackpropFilterGrad at 0x1264c9048>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3D (<function _Conv3DGrad at 0x1264c90d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropInputV2 (<function _Conv3DBackpropInputGrad at 0x1264c9158>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropFilterV2 (<function _Conv3DBackpropFilterGrad at 0x1264c91e0>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3D (<function _AvgPool3DGrad at 0x1264c9268>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3DGrad (<function _AvgPool3DGradGrad at 0x1264c92f0>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3D (<function _MaxPool3DGrad at 0x1264c9378>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGrad (<function _MaxPool3DGradGrad at 0x1264c9400>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGradGrad (<function _MaxPool3DGradGradGrad at 0x1264c9488>) in gradient.\n",
      "tensorflow: Level 1: Registering Softmax (<function _SoftmaxGrad at 0x1264c9510>) in gradient.\n",
      "tensorflow: Level 1: Registering LogSoftmax (<function _LogSoftmaxGrad at 0x1264c9598>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAdd (<function _BiasAddGrad at 0x1264c9620>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddGrad (<function _BiasAddGradGrad at 0x1264c96a8>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddV1 (<function _BiasAddGradV1 at 0x1264c9730>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu (<function _ReluGrad at 0x1264c97b8>) in gradient.\n",
      "tensorflow: Level 1: Registering EluGrad (<function _EluGradGrad at 0x1264c9840>) in gradient.\n",
      "tensorflow: Level 1: Registering SeluGrad (<function _SeluGradGrad at 0x1264c98c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6 (<function _Relu6Grad at 0x1264c9950>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6Grad (<function _Relu6GradGrad at 0x1264c99d8>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyRelu (<function _LeakyReluGrad at 0x1264c9a60>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyReluGrad (<function _LeakyReluGradGrad at 0x1264c9ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Elu (<function _EluGrad at 0x1264c9b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Selu (<function _SeluGrad at 0x1264c9c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Softplus (<function _SoftplusGrad at 0x1264c9d08>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftplusGrad (<function _SoftplusGradGrad at 0x1264c9d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Softsign (<function _SoftsignGrad at 0x1264c9e18>) in gradient.\n",
      "tensorflow: Level 1: Registering ReluGrad (<function _ReluGradGrad at 0x1264c9ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftmaxCrossEntropyWithLogits (<function _SoftmaxCrossEntropyWithLogitsGrad at 0x1264cf048>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmaxCrossEntropyWithLogits (<function _SparseSoftmaxCrossEntropyWithLogitsGrad at 0x1264cf0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D (<function _Conv2DGrad at 0x1264cf158>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative (<function _DepthwiseConv2dNativeGrad at 0x1264cf1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Dilation2D (<function _Dilation2DGrad at 0x1264cf268>) in gradient.\n",
      "tensorflow: Level 1: Registering LRN (<function _LRNGrad at 0x1264cf2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool (<function _AvgPoolGrad at 0x1264cf400>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPoolGrad (<function _AvgPoolGradGrad at 0x1264cf488>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool (<function _MaxPoolGrad at 0x1264cf510>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolV2 (<function _MaxPoolGradV2 at 0x1264cf598>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolWithArgmax (<function _MaxPoolGradWithArgmax at 0x1264cf620>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGrad (<function _MaxPoolGradGrad at 0x1264cf6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradV2 (<function _MaxPoolGradGradV2 at 0x1264cf730>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradGrad (<function _MaxPoolGradGradGrad at 0x1264cf7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalMaxPool (<function _FractionalMaxPoolGrad at 0x1264cf840>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalAvgPool (<function _FractionalAvgPoolGrad at 0x1264cf8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchNormWithGlobalNormalization (<function _BatchNormWithGlobalNormalizationGrad at 0x1264cf950>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNorm (<function _FusedBatchNormGrad at 0x1264cfa60>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormV2 (<function _FusedBatchNormV2Grad at 0x1264cfae8>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGrad (<function _FusedBatchNormGradGrad at 0x1264cfbf8>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGradV2 (<function _FusedBatchNormGradGradV2 at 0x1264cfc80>) in gradient.\n",
      "tensorflow: Level 1: Registering L2Loss (<function _L2LossGrad at 0x1264cfd08>) in gradient.\n",
      "tensorflow: Level 1: Registering TopKV2 (<function _TopKGrad at 0x1264cfd90>) in gradient.\n",
      "tensorflow: Level 1: Registering TopK (<function _TopKGrad at 0x1264cfd90>) in gradient.\n",
      "tensorflow: Level 1: Registering NthElement (<function _NthElementGrad at 0x1264cfe18>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCLoss (<function _CTCLossGrad at 0x1264cfea0>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCGreedyDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering CTCBeamSearchDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicPartition (<function _DynamicPartitionGrads at 0x1264dc158>) in gradient.\n",
      "tensorflow: Level 1: Registering ParallelDynamicStitch (<function _DynamicStitchGrads at 0x1264dc730>) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicStitch (<function _DynamicStitchGrads at 0x1264dc730>) in gradient.\n",
      "tensorflow: Level 1: Registering Queue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering Stack (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPush (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPop (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandle (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandleV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering DeleteSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SetSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToDenseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering NcclAllReduce (<function _all_sum_grad at 0x126560f28>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclReduce (<function _reduce_sum_grad at 0x126583268>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclBroadcast (<function _broadcast_grad at 0x126583378>) in gradient.\n",
      "tensorflow: Level 1: Registering Pack (<function _PackGrad at 0x1265e3730>) in gradient.\n",
      "tensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x1265e3a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Concat (<function _ConcatGrad at 0x1265e3b70>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatV2 (<function _ConcatGradV2 at 0x1265e3bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatOffset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Slice (<function _SliceGrad at 0x1265e3c80>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSlice (<function _StridedSliceGrad at 0x1265e3d08>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSliceGrad (<function _StridedSliceGradGrad at 0x1265e3d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Split (<function _SplitGrad at 0x1265e3e18>) in gradient.\n",
      "tensorflow: Level 1: Registering SplitV (<function _SplitVGrad at 0x1265e3ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Const (None) in gradient.\n",
      "tensorflow: Level 1: Registering Diag (<function _DiagGrad at 0x1265e3f28>) in gradient.\n",
      "tensorflow: Level 1: Registering DiagPart (<function _DiagPartGrad at 0x126604048>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiag (<function _MatrixDiagGrad at 0x1266040d0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiagPart (<function _MatrixDiagPartGrad at 0x126604158>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSetDiag (<function _MatrixSetDiagGrad at 0x1266041e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixBandPart (<function _MatrixBandPartGrad at 0x126604268>) in gradient.\n",
      "tensorflow: Level 1: Registering EditDistance (None) in gradient.\n",
      "tensorflow: Level 1: Registering Fill (<function _FillGrad at 0x1266042f0>) in gradient.\n",
      "tensorflow: Level 1: Registering ZerosLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering OnesLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering PreventGradient (<function _PreventGradientGrad at 0x126604378>) in gradient.\n",
      "tensorflow: Level 1: Registering Gather (<function _GatherGrad at 0x126604400>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherV2 (<function _GatherV2Grad at 0x126604488>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherNd (<function _GatherNdGrad at 0x126604510>) in gradient.\n",
      "tensorflow: Level 1: Registering CheckNumerics (<function _CheckNumericsGrad at 0x126604598>) in gradient.\n",
      "tensorflow: Level 1: Registering Identity (<function _IdGrad at 0x126604620>) in gradient.\n",
      "tensorflow: Level 1: Registering PlaceholderWithDefault (<function _IdGrad at 0x126604620>) in gradient.\n",
      "tensorflow: Level 1: Registering RefIdentity (<function _RefIdGrad at 0x1266046a8>) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityN (<function _IdNGrad at 0x126604730>) in gradient.\n",
      "tensorflow: Level 1: Registering StopGradient (None) in gradient.\n",
      "tensorflow: Level 1: Registering Reshape (<function _ReshapeGrad at 0x1266047b8>) in gradient.\n",
      "tensorflow: Level 1: Registering InvertPermutation (None) in gradient.\n",
      "tensorflow: Level 1: Registering ExpandDims (<function _ExpandDimsGrad at 0x1266048c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Squeeze (<function _SqueezeGrad at 0x126604950>) in gradient.\n",
      "tensorflow: Level 1: Registering Transpose (<function _TransposeGrad at 0x1266049d8>) in gradient.\n",
      "tensorflow: Level 1: Registering ConjugateTranspose (<function _ConjugateTransposeGrad at 0x126604a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Shape (None) in gradient.\n",
      "tensorflow: Level 1: Registering ShapeN (None) in gradient.\n",
      "tensorflow: Level 1: Registering Rank (None) in gradient.\n",
      "tensorflow: Level 1: Registering Size (None) in gradient.\n",
      "tensorflow: Level 1: Registering Tile (<function _TileGrad at 0x126604ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastGradientArgs (None) in gradient.\n",
      "tensorflow: Level 1: Registering Pad (<function _PadGrad at 0x126604b70>) in gradient.\n",
      "tensorflow: Level 1: Registering PadV2 (<function _PadGrad at 0x126604b70>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseSequence (<function _ReverseSequenceGrad at 0x126604c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Reverse (<function _ReverseGrad at 0x126604d08>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseV2 (<function _ReverseV2Grad at 0x126604d90>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatch (<function _SpaceToBatchGrad at 0x126604e18>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatchND (<function _SpaceToBatchNDGrad at 0x126604ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpace (<function _BatchToSpaceGrad at 0x126604f28>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpaceND (<function _BatchToSpaceNDGrad at 0x12660d048>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToDepth (<function _SpaceToDepthGrad at 0x12660d0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthToSpace (<function _DepthToSpaceGrad at 0x12660d158>) in gradient.\n",
      "tensorflow: Level 1: Registering OneHot (None) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPad (<function _MirrorPadGrad at 0x12660d1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPadGrad (<function _MirrorPadGradGrad at 0x12660d268>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantize (<function _QuantizeAndDequantizeGrad at 0x12660d2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV2 (<function _QuantizeAndDequantizeV2Grad at 0x12660d378>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV3 (<function _QuantizeAndDequantizeV3Grad at 0x12660d400>) in gradient.\n",
      "tensorflow: Level 1: Registering ExtractImagePatches (<function _ExtractImagePatchesGrad at 0x12660d488>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNd (<function _ScatterNdGrad at 0x12660d510>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterUpdate (<function _TensorScatterUpdateGrad at 0x12660d598>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterAdd (<function _TensorScatterAddGrad at 0x12660d620>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterSub (<function _TensorScatterSubGrad at 0x12660d6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdNonAliasingAdd (<function _ScatterNdNonAliasingAddGrad at 0x12660d730>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastTo (<function _BroadcastToGrad at 0x12660d7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Switch (<function _SwitchGrad at 0x12660d840>) in gradient.\n",
      "tensorflow: Level 1: Registering RefSwitch (<function _SwitchGrad at 0x12660d840>) in gradient.\n",
      "tensorflow: Level 1: Registering Merge (<function _MergeGrad at 0x12660d8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering RefMerge (<function _RefMergeGrad at 0x12660d950>) in gradient.\n",
      "tensorflow: Level 1: Registering Exit (<function _ExitGrad at 0x12660d9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering RefExit (<function _ExitGrad at 0x12660d9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering NextIteration (<function _NextIterationGrad at 0x12660da60>) in gradient.\n",
      "tensorflow: Level 1: Registering RefNextIteration (<function _RefNextIterationGrad at 0x12660dae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Enter (<function _EnterGrad at 0x12660db70>) in gradient.\n",
      "tensorflow: Level 1: Registering RefEnter (<function _RefEnterGrad at 0x12660dbf8>) in gradient.\n",
      "tensorflow: Level 1: Registering LoopCond (<function _LoopCondGrad at 0x12660dc80>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeNearestNeighbor (<function _ResizeNearestNeighborGrad at 0x12660dd08>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBilinear (<function _ResizeBilinearGrad at 0x12662dd90>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBicubic (<function _ResizeBicubicGrad at 0x12662de18>) in gradient.\n",
      "tensorflow: Level 1: Registering CropAndResize (<function _CropAndResizeGrad at 0x12662dea0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixInverse (<function _MatrixInverseGrad at 0x12662df28>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDeterminant (<function _MatrixDeterminantGrad at 0x126640378>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSquareRoot (<function _MatrixSquareRootGrad at 0x126640ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering LogMatrixDeterminant (<function _LogMatrixDeterminantGrad at 0x126640f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Cholesky (<function _CholeskyGrad at 0x126659048>) in gradient.\n",
      "tensorflow: Level 1: Registering Qr (<function _QrGrad at 0x1266590d0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolve (<function _MatrixSolveGrad at 0x1266591e0>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolveLs (<function _MatrixSolveLsGrad at 0x126659268>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixTriangularSolve (<function _MatrixTriangularSolveGrad at 0x1266592f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SelfAdjointEigV2 (<function _SelfAdjointEigV2Grad at 0x126659378>) in gradient.\n",
      "tensorflow: Level 1: Registering Svd (<function _SvdGrad at 0x126659400>) in gradient.\n",
      "tensorflow: Level 1: Registering Print (<function _PrintGrad at 0x1266597b8>) in gradient.\n",
      "tensorflow: Level 1: Registering HistogramSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ImageSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MergeSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScalarSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering Timestamp (None) in gradient.\n",
      "tensorflow: Level 1: Registering Roll (<function _RollGrad at 0x126659ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMax (<function _ArgMaxGrad at 0x126660bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMin (<function _ArgMinGrad at 0x126660c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Sum (<function _SumGrad at 0x126660d08>) in gradient.\n",
      "tensorflow: Level 1: Registering Max (<function _MaxGrad at 0x126660ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Min (<function _MinGrad at 0x12667a048>) in gradient.\n",
      "tensorflow: Level 1: Registering Mean (<function _MeanGrad at 0x12667a158>) in gradient.\n",
      "tensorflow: Level 1: Registering Prod (<function _ProdGrad at 0x12667a1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentSum (<function _SegmentSumGrad at 0x12667a268>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMean (<function _SegmentMeanGrad at 0x12667a2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSum (<function _SparseSegmentSumGrad at 0x12667a378>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSumWithNumSegments (<function _SparseSegmentSumWithNumSegmentsGrad at 0x12667a400>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMean (<function _SparseSegmentMeanGrad at 0x12667a488>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMeanWithNumSegments (<function _SparseSegmentMeanWithNumSegmentsGrad at 0x12667a510>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtN (<function _SparseSegmentSqrtNGrad at 0x12667a598>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtNWithNumSegments (<function _SparseSegmentSqrtNWithNumSegmentsGrad at 0x12667a620>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMin (<function _SegmentMinGrad at 0x12667a730>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMax (<function _SegmentMaxGrad at 0x12667a7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentSum (<function _UnsortedSegmentSumGrad at 0x12667a950>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMax (<function _UnsortedSegmentMaxGrad at 0x12667a9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMin (<function _UnsortedSegmentMinGrad at 0x12667aa60>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentProd (<function _UnsortedSegmentProdGrad at 0x12667aae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Abs (<function _AbsGrad at 0x12667ab70>) in gradient.\n",
      "tensorflow: Level 1: Registering Neg (<function _NegGrad at 0x12667ac80>) in gradient.\n",
      "tensorflow: Level 1: Registering Inv (<function _InvGrad at 0x12667ad90>) in gradient.\n",
      "tensorflow: Level 1: Registering Reciprocal (<function _ReciprocalGrad at 0x12667aea0>) in gradient.\n",
      "tensorflow: Level 1: Registering InvGrad (<function _InvGradGrad at 0x12667af28>) in gradient.\n",
      "tensorflow: Level 1: Registering ReciprocalGrad (<function _ReciprocalGradGrad at 0x12667e048>) in gradient.\n",
      "tensorflow: Level 1: Registering Square (<function _SquareGrad at 0x12667e0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sqrt (<function _SqrtGrad at 0x12667e158>) in gradient.\n",
      "tensorflow: Level 1: Registering SqrtGrad (<function _SqrtGradGrad at 0x12667e1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Rsqrt (<function _RsqrtGrad at 0x12667e268>) in gradient.\n",
      "tensorflow: Level 1: Registering RsqrtGrad (<function _RsqrtGradGrad at 0x12667e2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering Exp (<function _ExpGrad at 0x12667e378>) in gradient.\n",
      "tensorflow: Level 1: Registering Expm1 (<function _Expm1Grad at 0x12667e488>) in gradient.\n",
      "tensorflow: Level 1: Registering Log (<function _LogGrad at 0x12667e510>) in gradient.\n",
      "tensorflow: Level 1: Registering Log1p (<function _Log1pGrad at 0x12667e620>) in gradient.\n",
      "tensorflow: Level 1: Registering Xlogy (<function _XLogyGrad at 0x12667e6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Xdivy (<function _XDivyGrad at 0x12667e730>) in gradient.\n",
      "tensorflow: Level 1: Registering Sinh (<function _SinhGrad at 0x12667e7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Cosh (<function _CoshGrad at 0x12667e840>) in gradient.\n",
      "tensorflow: Level 1: Registering Tanh (<function _TanhGrad at 0x12667e8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Asinh (<function _AsinhGrad at 0x12667e950>) in gradient.\n",
      "tensorflow: Level 1: Registering Acosh (<function _AcoshGrad at 0x12667e9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Atanh (<function _AtanhGrad at 0x12667ea60>) in gradient.\n",
      "tensorflow: Level 1: Registering TanhGrad (<function _TanhGradGrad at 0x12667eae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Erf (<function _ErfGrad at 0x12667eb70>) in gradient.\n",
      "tensorflow: Level 1: Registering Erfc (<function _ErfcGrad at 0x12667ec80>) in gradient.\n",
      "tensorflow: Level 1: Registering Lgamma (<function _LgammaGrad at 0x12667ed08>) in gradient.\n",
      "tensorflow: Level 1: Registering Digamma (<function _DigammaGrad at 0x12667ed90>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI0e (<function _BesselI0eGrad at 0x12667ee18>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI1e (<function _BesselI1eGrad at 0x12667eea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Igamma (<function _IgammaGrad at 0x12667ef28>) in gradient.\n",
      "tensorflow: Level 1: Registering Igammac (<function _IgammacGrad at 0x126682048>) in gradient.\n",
      "tensorflow: Level 1: Registering Betainc (<function _BetaincGrad at 0x1266820d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Zeta (<function _ZetaGrad at 0x126682158>) in gradient.\n",
      "tensorflow: Level 1: Registering Polygamma (<function _PolygammaGrad at 0x1266821e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sigmoid (<function _SigmoidGrad at 0x126682268>) in gradient.\n",
      "tensorflow: Level 1: Registering SigmoidGrad (<function _SigmoidGradGrad at 0x1266822f0>) in gradient.\n",
      "tensorflow: Level 1: Registering Sign (<function _SignGrad at 0x126682378>) in gradient.\n",
      "tensorflow: Level 1: Registering Sin (<function _SinGrad at 0x126682400>) in gradient.\n",
      "tensorflow: Level 1: Registering Cos (<function _CosGrad at 0x126682510>) in gradient.\n",
      "tensorflow: Level 1: Registering Tan (<function _TanGrad at 0x126682620>) in gradient.\n",
      "tensorflow: Level 1: Registering Asin (<function _AsinGrad at 0x126682730>) in gradient.\n",
      "tensorflow: Level 1: Registering Acos (<function _AcosGrad at 0x1266827b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan (<function _AtanGrad at 0x126682840>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan2 (<function _Atan2Grad at 0x1266828c8>) in gradient.\n",
      "tensorflow: Level 1: Registering AddN (<function _AddNGrad at 0x126682950>) in gradient.\n",
      "tensorflow: Level 1: Registering Add (<function _AddGrad at 0x126682a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Sub (<function _SubGrad at 0x126682b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Mul (<function _MulGrad at 0x126682c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Div (<function _DivGrad at 0x126682d90>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorDiv (<function _FloorDivGrad at 0x126682ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorMod (<function _FloorModGrad at 0x126682f28>) in gradient.\n",
      "tensorflow: Level 1: Registering TruncateDiv (<function _TruncateDivGrad at 0x126685048>) in gradient.\n",
      "tensorflow: Level 1: Registering RealDiv (<function _RealDivGrad at 0x1266850d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DivNoNan (<function _DivNoNanGrad at 0x126685158>) in gradient.\n",
      "tensorflow: Level 1: Registering Pow (<function _PowGrad at 0x1266851e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Maximum (<function _MaximumGrad at 0x126685378>) in gradient.\n",
      "tensorflow: Level 1: Registering Minimum (<function _MinimumGrad at 0x126685400>) in gradient.\n",
      "tensorflow: Level 1: Registering SquaredDifference (<function _SquaredDifferenceGrad at 0x126685488>) in gradient.\n",
      "tensorflow: Level 1: Registering Less (None) in gradient.\n",
      "tensorflow: Level 1: Registering LessEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Greater (None) in gradient.\n",
      "tensorflow: Level 1: Registering GreaterEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Equal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ApproximateEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering NotEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalAnd (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalOr (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalNot (None) in gradient.\n",
      "tensorflow: Level 1: Registering Select (<function _SelectGrad at 0x126685510>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul (<function _MatMulGrad at 0x126685598>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseMatMul (<function _SparseMatMulGrad at 0x126685620>) in gradient.\n",
      "tensorflow: Level 1: Registering Floor (<function _FloorGrad at 0x1266856a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Ceil (<function _CeilGrad at 0x126685730>) in gradient.\n",
      "tensorflow: Level 1: Registering Round (<function _RoundGrad at 0x1266857b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Rint (<function _RintGrad at 0x126685840>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchMatMul (<function _BatchMatMul at 0x1266858c8>) in gradient.\n",
      "tensorflow: Level 1: Registering Range (None) in gradient.\n",
      "tensorflow: Level 1: Registering LinSpace (None) in gradient.\n",
      "tensorflow: Level 1: Registering Complex (<function _ComplexGrad at 0x126685950>) in gradient.\n",
      "tensorflow: Level 1: Registering Real (<function _RealGrad at 0x1266859d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Imag (<function _ImagGrad at 0x126685a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Angle (<function _AngleGrad at 0x126685ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Conj (<function _ConjGrad at 0x126685b70>) in gradient.\n",
      "tensorflow: Level 1: Registering ComplexAbs (<function _ComplexAbsGrad at 0x126685bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering Cast (<function _CastGrad at 0x126685c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Cross (<function _CrossGrad at 0x126685d08>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumsum (<function _CumsumGrad at 0x126685d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumprod (<function _CumprodGrad at 0x126685e18>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalFromValue (<function _OptionalFromValueGrad at 0x126685ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalGetValue (<function _OptionalGetValueGrad at 0x126685f28>) in gradient.\n",
      "tensorflow: Level 1: Registering RandomGamma (<function _RandomGammaGrad at 0x12668a0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeRaw (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParseTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SerializeTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToNumber (None) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNN (<function _cudnn_rnn_backward at 0x125f07840>) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNNV2 (<function _cudnn_rnn_backward_v2 at 0x126809b70>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAddGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseConcat (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToDense (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReorder (<function _SparseReorderGrad at 0x126809bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAdd (<function _SparseAddGrad at 0x126809d90>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseAdd (<function _SparseTensorDenseAddGrad at 0x126809e18>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReduceSum (<function _SparseReduceSumGrad at 0x126809ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSlice (<function _SparseSliceGrad at 0x126809f28>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseMatMul (<function _SparseTensorDenseMatMulGrad at 0x126814048>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseAdd (<function _SparseDenseCwiseAddGrad at 0x1268140d0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseMul (<function _SparseDenseCwiseMulGrad at 0x1268141e0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseDiv (<function _SparseDenseCwiseDivGrad at 0x126814268>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmax (<function _SparseSoftmaxGrad at 0x1268142f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMaximum (<function _SparseSparseMaximumGrad at 0x126814378>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMinimum (<function _SparseSparseMinimumGrad at 0x126814400>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseFillEmptyRows (<function _SparseFillEmptyRowsGrad at 0x126814488>) in gradient.\n",
      "tensorflow: Level 1: Registering Assign (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdUpdate (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArray (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySize (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradWithShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV3 (<function _TensorArrayReadGrad at 0x126814730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV2 (<function _TensorArrayReadGrad at 0x126814730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayRead (<function _TensorArrayReadGrad at 0x126814730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV3 (<function _TensorArrayWriteGrad at 0x1268147b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV2 (<function _TensorArrayWriteGrad at 0x1268147b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWrite (<function _TensorArrayWriteGrad at 0x1268147b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV3 (<function _TensorArrayGatherGrad at 0x126814840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV2 (<function _TensorArrayGatherGrad at 0x126814840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGather (<function _TensorArrayGatherGrad at 0x126814840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatterV3 (<function _TensorArrayScatterGrad at 0x1268148c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatterV2 (<function _TensorArrayScatterGrad at 0x1268148c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayScatter (<function _TensorArrayScatterGrad at 0x1268148c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV3 (<function _TensorArrayConcatGrad at 0x126814950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV2 (<function _TensorArrayConcatGrad at 0x126814950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayConcat (<function _TensorArrayConcatGrad at 0x126814950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplitV3 (<function _TensorArraySplitGrad at 0x1268149d8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplitV2 (<function _TensorArraySplitGrad at 0x1268149d8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySplit (<function _TensorArraySplitGrad at 0x1268149d8>) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableFind (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableFindV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableInsert (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableInsertV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering LookupTableSizeV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering HashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering HashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFile (None) in gradient.\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFileV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableDenseHashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableDenseHashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTable (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensors (None) in gradient.\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensorsV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering RaggedTensorToSparse (<function _ragged_tensor_to_sparse_gradient at 0x1268a1400>) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessMultinomial (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomUniform (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessRandomUniformInt (None) in gradient.\n",
      "tensorflow: Level 1: Registering StatelessTruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomCrop (None) in gradient.\n",
      "tensorflow: Level 1: Registering RGBToHSV (None) in gradient.\n",
      "tensorflow: Level 1: Registering HSVToRGB (None) in gradient.\n",
      "tensorflow: Level 1: Registering DrawBoundingBoxes (None) in gradient.\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBox (None) in gradient.\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBoxV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering ExtractGlimpse (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppression (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionWithOverlaps (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseAnd (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseOr (None) in gradient.\n",
      "tensorflow: Level 1: Registering BitwiseXor (None) in gradient.\n",
      "tensorflow: Level 1: Registering Invert (None) in gradient.\n",
      "tensorflow: Level 1: Registering PopulationCount (None) in gradient.\n",
      "tensorflow: Level 1: Registering LeftShift (None) in gradient.\n",
      "tensorflow: Level 1: Registering RightShift (None) in gradient.\n",
      "tensorflow: Level 1: Registering FFT (<function _fft_grad at 0x13314e400>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT (<function _ifft_grad at 0x13314e510>) in gradient.\n",
      "tensorflow: Level 1: Registering FFT2D (<function _fft2d_grad at 0x13314e598>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT2D (<function _ifft2d_grad at 0x13314e620>) in gradient.\n",
      "tensorflow: Level 1: Registering FFT3D (<function _fft3d_grad at 0x13314e6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering IFFT3D (<function _ifft3d_grad at 0x13314e730>) in gradient.\n",
      "tensorflow: Level 1: Registering RFFT (<function _rfft_grad_helper.<locals>._grad at 0x13314e8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering IRFFT (<function _irfft_grad_helper.<locals>._grad at 0x13314e950>) in gradient.\n",
      "tensorflow: Level 1: Registering RFFT2D (<function _rfft_grad_helper.<locals>._grad at 0x13314e9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering IRFFT2D (<function _irfft_grad_helper.<locals>._grad at 0x13314ea60>) in gradient.\n",
      "tensorflow: Level 1: Registering Reciprocal,flops (<function _reciprocal_flops at 0x1331991e0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Square,flops (<function _square_flops at 0x133199268>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Rsqrt,flops (<function _rsqrt_flops at 0x1331992f0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Log,flops (<function _log_flops at 0x133199378>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Neg,flops (<function _neg_flops at 0x133199400>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AssignSub,flops (<function _assign_sub_flops at 0x133199488>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AssignAdd,flops (<function _assign_add_flops at 0x133199510>) in statistical functions.\n",
      "tensorflow: Level 1: Registering L2Loss,flops (<function _l2_loss_flops at 0x133199598>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Softmax,flops (<function _softmax_flops at 0x133199620>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Add,flops (<function _add_flops at 0x133199730>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Sub,flops (<function _sub_flops at 0x1331997b8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Mul,flops (<function _mul_flops at 0x133199840>) in statistical functions.\n",
      "tensorflow: Level 1: Registering RealDiv,flops (<function _real_div_flops at 0x1331998c8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Maximum,flops (<function _maximum_flops at 0x133199950>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Minimum,flops (<function _minimum_flops at 0x1331999d8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Pow,flops (<function _pow_flops at 0x133199a60>) in statistical functions.\n",
      "tensorflow: Level 1: Registering RsqrtGrad,flops (<function _rsqrt_grad_flops at 0x133199ae8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering GreaterEqual,flops (<function _greater_equal_flops at 0x133199b70>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Greater,flops (<function _greater_flops at 0x133199bf8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering LessEqual,flops (<function _less_equal_flops at 0x133199c80>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Less,flops (<function _less_flops at 0x133199d08>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Equal,flops (<function _equal_flops at 0x133199d90>) in statistical functions.\n",
      "tensorflow: Level 1: Registering NotEqual,flops (<function _not_equal_flops at 0x133199e18>) in statistical functions.\n",
      "tensorflow: Level 1: Registering SquaredDifference,flops (<function _squared_difference_flops at 0x133199ea0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Mean,flops (<function _mean_flops at 0x1331a2048>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Sum,flops (<function _sum_flops at 0x1331a20d0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering ArgMax,flops (<function _arg_max_flops at 0x1331a2158>) in statistical functions.\n",
      "tensorflow: Level 1: Registering ArgMin,flops (<function _arg_min_flops at 0x1331a21e0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering BiasAddGrad,flops (<function _bias_add_grad_flops at 0x1331a2268>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AvgPool,flops (<function _avg_pool_flops at 0x1331a2400>) in statistical functions.\n",
      "tensorflow: Level 1: Registering MaxPool,flops (<function _max_pool_flops at 0x1331a2488>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AvgPoolGrad,flops (<function _avg_pool_grad_flops at 0x1331a2510>) in statistical functions.\n",
      "tensorflow: Level 1: Registering MaxPoolGrad,flops (<function _max_pool_grad_flops at 0x1331a2598>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput,flops (<function _conv_2d_backprop_input_flops at 0x1331a2620>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter,flops (<function _conv_2d_backprop_filter_flops at 0x1331a26a8>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AddN,flops (<function _add_n_flops at 0x1331a2730>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Fact (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x125945ea0>) in default shape functions.\n",
      "tensorflow: Level 1: Registering SdcaFprint (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaOptimizer (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaOptimizerV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering SdcaShrinkL1 (None) in gradient.\n",
      "tensorflow: Level 1: Registering queue_runners ((<class 'tensorflow.core.protobuf.queue_runner_pb2.QueueRunnerDef'>, <function QueueRunner.to_proto at 0x13321cf28>, <function QueueRunner.from_proto at 0x13322a048>)) in proto functions.\n",
      "tensorflow: Level 1: Registering GenerateVocabRemapping (None) in gradient.\n",
      "tensorflow: Level 1: Registering LoadAndRemapMatrix (None) in gradient.\n",
      "--------------------- >> end captured logging << ---------------------\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_environment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr,x_tr = preproc.read_data('data/rock-lyrics-train.csv', preprocessor = preproc.bag_of_words)\n",
    "y_dv,x_dv = preproc.read_data('data/rock-lyrics-dev.csv', preprocessor = preproc.bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_te,x_te = preproc.read_data('data/rock-lyrics-test-hidden.csv', preprocessor = preproc.bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen words\n",
    "\n",
    "One challenge for classification is that words will appear in the test data that do not appear in the training data. Compute the number of words that appear in `rock-lyrics-dev.csv`, but not in `rock-lyrics-train.csv`. To do this, implement the following deliverables:\n",
    "\n",
    "- **Deliverable 1.2**: implement `snlp.preproc.aggregate_counts`, a counter of all words in a list of bags-of-words. \n",
    "- **Deliverable 1.3**: implement `snlp.preproc.compute_oov`, returning a list of words that appear in one list of bags-of-words, but not another.  \n",
    "- **Tests**: `tests/test_preproc.py:test_d1_2_agg`, `tests/test_preproc.py:test_d1_3a_oov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write fast code, you can find bottlenecks using the %%timeit cell magic. \n",
    "\n",
    "Here I'm evaluating two different implementations of `aggregate_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 ms ± 6.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preproc.aggregate_counts(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dv = preproc.aggregate_counts(x_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the most common items in a counter by calling counts.most_common()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4678), ('I', 4005), ('you', 3456), ('to', 2628), ('a', 2363)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_dv.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tr = preproc.aggregate_counts(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3145"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preproc.compute_oov(counts_dv,counts_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33146"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preproc.compute_oov(counts_tr,counts_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2723651164804711"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.oov_rate(counts_dv,counts_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27% of the words in the dev set do not appear in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power laws\n",
    "\n",
    "Word count distributions are said to follow [power law](https://en.wikipedia.org/wiki/Power_law) distributions. \n",
    "\n",
    "In practice, this means that a log-log plot of frequency against rank is nearly linear. Let's see if this holds for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog([val for word,val in counts_tr.most_common()])\n",
    "plt.loglog([val for word,val in counts_dv.most_common()])\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend(['training set','dev set']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would this curve look like if it were not plotted in log space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the vocabulary\n",
    "\n",
    "Let's prune the vocabulary to include only words that appear at least ten times in the training data.\n",
    "\n",
    "- **Deliverable 1.4:** Implement `preproc.prune_vocabulary` \n",
    "- **Test**: `tests/test_preproc.py:test_d1_4_prune`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_pruned, vocab = preproc.prune_vocabulary(counts_tr,x_tr,10)\n",
    "x_dv_pruned, _ = preproc.prune_vocabulary(counts_tr,x_dv,10)\n",
    "x_te_pruned, _ = preproc.prune_vocabulary(counts_tr,x_te,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5992"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear classification\n",
    "\n",
    "Now you'll implement the linear classification rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "You will use these functions in all classifiers in this assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlp import clf_base\n",
    "reload(clf_base)\n",
    "\n",
    "from snlp import constants\n",
    "reload(constants);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall from class and the reading that the feature function vector $f(x,y)$ can be viewed as a dict, in which the values are counts, and the keys are tuples $(y,x_j)$, where $y$ is a label and $x_j$ is a base feature.\n",
    "\n",
    "- **Deliverable 2.1**: Implement the function ```make_feature_vector``` in ```clf_base.py```. \n",
    "- **Test**: `tests/test_classifier.py:test_d2_1_featvec`\n",
    "\n",
    "Note that you must also include the offset feature, ```snlp.constants.OFFSET```.\n",
    "\n",
    "Desired output is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.749s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_classifier.py:test_d2_1_featvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = clf_base.make_feature_vector({'test':1,'case':2},'1980s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('1980s', '**OFFSET**'): 1, ('1980s', 'test'): 1, ('1980s', 'case'): 2}\n"
     ]
    }
   ],
   "source": [
    "print(fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the entire set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1980s', '1990s', 'pre-1980s', '2000s'}\n"
     ]
    }
   ],
   "source": [
    "labels = set(y_tr) #figure out all possible labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the prediction rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "- **Deliverable 2.2**: Implement the function ```predict``` in ```clf_base.py```. (1 point for 4650, 0.5 points for 7650)\n",
    "- **Test**: `tests/test_classifier.py:test_d2_2_predict`\n",
    "\n",
    "The output should be:\n",
    "\n",
    "- A predicted label\n",
    "- The scores of all labels\n",
    "\n",
    "This function will be called **a lot**, so try to make it fast. You don't need to do anything crazy, but avoid making your code do silly extra work. It's worth trying out a couple different versions using %%timeit.\n",
    "\n",
    "You can test this function using these simple hand-crafted weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight vectors must be defaultdicts\n",
    "theta_hand = defaultdict(float,\n",
    "                         {('2000s','money'):0.1,\n",
    "                          ('2000s','name'):0.2,\n",
    "                          ('1980s','tonight'):0.1,\n",
    "                          ('2000s','man'):0.1,\n",
    "                          ('1990s','fly'):0.1,\n",
    "                          ('pre-1980s',constants.OFFSET):0.1\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pre-1980s', {'1980s': 0.0, '1990s': 0.0, 'pre-1980s': 0.1, '2000s': 0.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr_pruned[0],theta_hand,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how good these weights are, by evaluating on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlp import evaluation\n",
    "reload(evaluation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30544747081712065\n"
     ]
    }
   ],
   "source": [
    "# this applies your predict function to all the instances in ```x_dv```\n",
    "y_hat = clf_base.predict_all(x_dv_pruned,theta_hand,labels)\n",
    "print(evaluation.acc(y_hat,y_dv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes\n",
    "\n",
    "You'll now implement a Naive Bayes classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlp import naive_bayes\n",
    "reload(naive_bayes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.1**: (warmup) implement ```get_corpus_counts``` in ```naive_bayes.py```. (0.5 points)\n",
    "- **Test**: `tests/test_classifier.py:test_d3_1_corpus_counts`\n",
    "\n",
    "This function should compute the word counts for a given label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "eighties_counts = naive_bayes.get_corpus_counts(x_tr_pruned,y_tr,\"1980s\");\n",
    "print(eighties_counts['today'])\n",
    "print(eighties_counts['yesterday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.2**: Implement ```estimate_pxy``` in ```naive_bayes.py```. \n",
    "- **Test**: `tests/test_classifier.py:test_d3_2_pxy`\n",
    "\n",
    "This function should compute the *smoothed* multinomial distribution $\\log P(x \\mid y)$ for a given label $y$.\n",
    "\n",
    "Hint: note that this function takes the vocabulary as an argument. You have to assign a probability even for words that do not appear in documents with label $y$, if they are in the vocabulary.\n",
    "\n",
    "You can use ```get_corpus_counts``` in this function if you want to, but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nosetests tests/test_classifier.py:test_d3_2_pxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669.2000000000069"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'at': 499.60000000000895, 'ah': 169.59999999999795}\n",
    "\n",
    "sum(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pxy = naive_bayes.estimate_pxy(x_tr_pruned,y_tr,\"1980s\",0.1,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities must sum to one! (or very close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999802"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(list(log_pxy.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the log-probabilities of the words from the hand-tuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money': -7.969973834156985, 'name': -7.377406759792738, 'tonight': -6.9382388281494505, 'man': -6.3519475704903305, 'fly': -8.360722957632635, '**OFFSET**': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print({word:log_pxy[word] for (_,word),weight in theta_hand.items() if weight>0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pxy_more_smooth = naive_bayes.estimate_pxy(x_tr_pruned,y_tr,\"1980s\",10,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money': -8.173461476943206, 'name': -7.679803656799581, 'tonight': -7.287410630258769, 'man': -6.740405349915276, 'fly': -8.46826101716385, '**OFFSET**': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print({word:log_pxy_more_smooth[word] for (_,word),weight in theta_hand.items() if weight>0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.3**: Now you are ready to implement ```estimate_nb``` in ```naive_bayes.py```. \n",
    "- **Test**: `tests/test_classifier.py:test_d3_3a_nb`\n",
    "\n",
    "\n",
    "\n",
    "- The goal is that the score given by ```clf_base.predict``` is equal to the joint probability $P(x,y)$, as described in the notes.\n",
    "- Don't forget the offset feature, whose weights should be set to the prior $\\log P(y)$.\n",
    "- The log-probabilities for the offset feature should not be smoothed.\n",
    "- You can call the functions you have defined above, but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nosetests tests/test_classifier.py:test_d3_3a_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_nb = naive_bayes.estimate_nb(x_tr_pruned,y_tr,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000s',\n",
       " {'1980s': -1826.9832676531355,\n",
       "  '1990s': -1828.7902340901674,\n",
       "  'pre-1980s': -1858.4236481723424,\n",
       "  '2000s': -1778.670801110657})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr_pruned[155],theta_nb,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4805447470817121\n"
     ]
    }
   ],
   "source": [
    "y_hat = clf_base.predict_all(x_dv_pruned,theta_nb,labels)\n",
    "print(evaluation.acc(y_hat,y_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4805447470817121"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this block shows how we write and read predictions for evaluation\n",
    "evaluation.write_predictions(y_hat,'nb-dev.preds')\n",
    "y_hat_dv = evaluation.read_predictions('nb-dev.preds')\n",
    "evaluation.acc(y_hat_dv,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this block to write predictions for the test set\n",
    "y_hat = clf_base.predict_all(x_te_pruned,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-test.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best smoother "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.4**: Write a function in ```naive_bayes.py``` called ```find_best_smoother```, which finds the smoothing value that gives best performance on the dev data.  \n",
    "\n",
    "Your function should trying at least the following values in `vals` below.\n",
    "\n",
    "Then, using this smoothing value, run your Naive Bayes classifier on the test set, and output the results.\n",
    "\n",
    "This might be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
      " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
      " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n"
     ]
    }
   ],
   "source": [
    "vals = np.logspace(-3,2,11)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E\n",
      "======================================================================\n",
      "ERROR: Failure: ValueError (No such test test_d3_4a_nb_best)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/davidmortensen/anaconda3/lib/python3.7/site-packages/nose/failure.py\", line 42, in runTest\n",
      "    raise self.exc_class(self.exc_val)\n",
      "ValueError: No such test test_d3_4a_nb_best\n",
      "-------------------- >> begin captured logging << --------------------\n",
      "matplotlib: DEBUG: $HOME=/Users/davidmortensen\n",
      "matplotlib: DEBUG: matplotlib data path /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data\n",
      "matplotlib: DEBUG: loaded rc file /Users/davidmortensen/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc\n",
      "matplotlib: DEBUG: matplotlib version 2.2.3\n",
      "matplotlib: DEBUG: interactive is False\n",
      "matplotlib: DEBUG: platform is darwin\n",
      "matplotlib: DEBUG: loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', 'posixpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', '_bootlocale', '_locale', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'sphinxcontrib', 'zope', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'nose', 'nose.core', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 'token', 'weakref', '_weakrefset', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'difflib', 'pprint', 'unittest.suite', 'unittest.loader', 'fnmatch', 'unittest.main', 'argparse', 'gettext', 'locale', 'unittest.runner', 'unittest.signals', 'signal', 'nose.config', 'optparse', 'textwrap', 'errno', 'configparser', 'nose.util', 'inspect', 'dis', 'opcode', '_opcode', 'nose.pyversion', 'nose.plugins', 'nose.plugins.base', 'nose.plugins.manager', 'nose.failure', 'pickle', 'struct', '_struct', '_compat_pickle', '_pickle', 'pkg_resources', '__future__', 'zipfile', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'binascii', 'pkgutil', 'platform', 'subprocess', '_posixsubprocess', 'select', 'selectors', 'math', 'plistlib', 'datetime', '_datetime', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'base64', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'random', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'socket', '_socket', 'urllib', 'urllib.parse', 'email._parseaddr', 'calendar', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources.extern.six', 'pkg_resources._vendor.six', 'pkg_resources.extern.six.moves', 'pkg_resources._vendor.six.moves', 'pkg_resources.py31compat', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging._compat', 'pkg_resources.extern.packaging.requirements', 'copy', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.six.moves.urllib', 'pkg_resources.extern.packaging.markers', 'sysconfig', '_osx_support', '_sysconfigdata_m_darwin_darwin', 'nose.plugins.plugintest', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'nose.loader', 'nose.case', 'nose.importer', 'imp', 'nose.selector', 'nose.suite', 'nose.proxy', 'nose.result', 'nose.exc', 'nose.plugins.skip', 'nose.plugins.errorclass', 'nose.plugins.deprecated', 'nose.tools', 'nose.tools.nontrivial', 'nose.tools.trivial', 'nose.plugins.builtin', 'nose.plugins.attrib', 'nose.plugins.capture', 'nose.plugins.logcapture', 'nose.plugins.cover', 'nose.plugins.debug', 'pdb', 'cmd', 'bdb', 'code', 'codeop', 'glob', 'nose.plugins.doctests', 'doctest', 'nose.plugins.isolate', 'nose.plugins.failuredetail', 'nose.inspector', 'nose.plugins.prof', 'nose.plugins.testid', 'nose.plugins.multiprocess', 'queue', '_queue', 'nose.plugins.xunit', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'xml.sax.saxutils', 'urllib.request', 'http', 'http.client', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'ssl', '_ssl', 'urllib.error', 'urllib.response', '_scproxy', 'nose.plugins.allmodules', 'nose.plugins.collect', 'test_classifier', 'snlp', 'snlp.preproc', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._import_tools', 'numpy.add_newdocs', 'numpy.lib', 'numpy.lib.info', 'numpy.lib.type_check', 'numpy.core', 'numpy.core.info', 'numpy.core.multiarray', 'numpy.core.umath', 'numpy.core._internal', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'ntpath', 'ctypes', '_ctypes', 'ctypes._endian', 'numpy.core.numerictypes', 'numbers', 'numpy.core.numeric', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.shape_base', 'numpy.core.einsumfunc', 'numpy.testing', 'numpy.testing._private', 'numpy.testing._private.utils', 'gc', 'numpy.lib.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'numpy.testing._private.pytesttester', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.lib.function_base', 'numpy.lib.twodim_base', 'numpy.lib.histograms', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'ast', '_ast', 'numpy.linalg', 'numpy.linalg.info', 'numpy.linalg.linalg', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.stride_tricks', 'numpy.lib.mixins', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.scimath', 'numpy.lib.polynomial', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.core._multiarray_tests', 'numpy._distributor_init', 'numpy.fft', 'numpy.fft.info', 'numpy.fft.fftpack', 'numpy.fft.fftpack_lite', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random.info', 'cython_runtime', 'mtrand', 'numpy.random.mtrand', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'distutils', 'distutils.version', 'unicodedata', 'pandas.compat.chainmap', 'dateutil.parser', 'dateutil.parser._parser', 'six', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.parser.isoparser', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslib', 'pandas._libs.tslibs', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.np_datetime', '_cython_0_28_4', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.timestamps', 'pandas._libs.tslibs.fields', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.lib', 'pandas.core', 'pandas.core.config_init', 'pandas.core.config', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.printing', 'pandas.core.dtypes', 'pandas.core.dtypes.inference', 'pandas.io.formats.console', 'pandas.io.formats.terminal', 'pandas.core.api', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.core.dtypes.common', 'pandas._libs.algos', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.missing', 'pandas.core.common', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.util._validators', 'pandas.core.arrays.categorical', 'pandas.core.accessor', 'pandas.core.base', 'pandas.core.nanops', 'bottleneck', 'bottleneck.reduce', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.move', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck.version', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'pandas.core.missing', 'pandas.core.groupby', 'pandas.core.groupby.groupby', 'pandas.core.index', 'pandas.core.indexes', 'pandas.core.indexes.api', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.frequencies', 'pandas._libs.tslibs.resolution', 'pandas.tseries', 'pandas.tseries.offsets', 'pandas.core.tools', 'pandas.core.tools.datetimes', 'dateutil.easter', 'pandas._libs.tslibs.offsets', 'pandas.tseries.frequencies', 'pandas._libs.join', 'pandas.core.ops', 'pandas._libs.ops', 'pandas.core.indexes.frozen', 'pandas.core.dtypes.concat', 'pandas.core.sorting', 'pandas.core.strings', 'pandas.core.indexes.category', 'pandas.core.indexes.multi', 'pandas.core.indexes.interval', 'pandas._libs.interval', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.numeric', 'pandas.core.indexes.datetimelike', 'pandas.core.tools.timedeltas', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.range', 'pandas.core.indexes.period', 'pandas.core.frame', 'pandas.core.generic', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.internals', 'pandas._libs.internals', 'pandas.core.sparse', 'pandas.core.sparse.array', 'pandas._libs.sparse', 'pandas.io.formats.format', 'pandas.io.common', 'csv', '_csv', 'mmap', 'pandas.core.series', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._misc', 'pandas.plotting._style', 'pandas.plotting._compat', 'pandas.plotting._tools', 'pandas.plotting._core', 'pandas.plotting._converter', 'matplotlib', 'matplotlib.cbook', 'gzip', 'matplotlib.cbook.deprecation', 'matplotlib.cbook._backports', 'matplotlib.compat', 'matplotlib.compat.subprocess', 'matplotlib.rcsetup', 'matplotlib.testing', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'six.moves.urllib', 'six.moves.urllib.request', 'matplotlib._version']\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x1280a7400>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x1280a7730>) in gradient.\n",
      "tensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x1280a77b8>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x1282c7378>) in statistical functions.\n",
      "tensorflow: Level 1: Registering AccumulateNV2 (<function _accumulate_n_grad at 0x1282c76a8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcatLists (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListElementShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListLength (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBackBatch (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPushBack (<function _PushBackGrad at 0x12836c510>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListPopBack (<function _PopBackGrad at 0x12836c598>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListStack (<function _TensorListStackGrad at 0x12836c620>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListConcat (<function _TensorListConcatGrad at 0x12836c6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSplit (<function _TensorListSplitGrad at 0x12836c730>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListFromTensor (<function _TensorListFromTensorGrad at 0x12836c7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGetItem (<function _TensorListGetItemGrad at 0x12836c840>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListSetItem (<function _TensorListSetItemGrad at 0x12836c8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListGather (<function _TensorListGatherGrad at 0x12836c950>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorListScatter (<function _TensorListScatterGrad at 0x12836c9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <function CondContext.to_proto at 0x1283850d0>, <function CondContext.from_proto at 0x128385158>)) in proto functions.\n",
      "tensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <function WhileContext.to_proto at 0x128385f28>, <function WhileContext.from_proto at 0x1283890d0>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReadVariableOp (<function _ReadGrad at 0x1283f40d0>) in gradient.\n",
      "tensorflow: Level 1: Registering ResourceGather (<function _GatherGrad at 0x1283f4ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering trainable_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering moving_average_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering local_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering model_variables ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering global_step ((<class 'tensorflow.core.framework.variable_pb2.VariableDef'>, <function _to_proto_fn at 0x1283f4b70>, <function _from_proto_fn at 0x1283f4bf8>)) in proto functions.\n",
      "tensorflow: Level 1: Registering VarIsInitializedOp (None) in gradient.\n",
      "tensorflow: Level 1: Registering VariableShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomStandardNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParameterizedTruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering TruncatedNormal (None) in gradient.\n",
      "tensorflow: Level 1: Registering RandomUniform (None) in gradient.\n",
      "tensorflow: Level 1: Registering Multinomial (None) in gradient.\n",
      "tensorflow: Level 1: Registering EnsureShape (<function _ensure_shape_grad at 0x1284e3d08>) in gradient.\n",
      "tensorflow: Level 1: Registering EagerPyFunc (<function _EagerPyFuncGrad at 0x1284e99d8>) in gradient.\n",
      "tensorflow: Level 1: Registering PyFunc (None) in gradient.\n",
      "tensorflow: Level 1: Registering PyFuncStateless (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRead (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReadUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumRecordsProduced (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderNumWorkUnitsCompleted (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderSerializeState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderRestoreState (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReaderReset (None) in gradient.\n",
      "tensorflow: Level 1: Registering WholeFileReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TextLineReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering FixedLengthRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering TFRecordReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering LMDBReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityReader (None) in gradient.\n",
      "tensorflow: Level 1: Registering RegexReplace (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucket (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketFast (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToHashBucketStrong (None) in gradient.\n",
      "tensorflow: Level 1: Registering ReduceJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringJoin (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringSplit (None) in gradient.\n",
      "tensorflow: Level 1: Registering AsString (None) in gradient.\n",
      "tensorflow: Level 1: Registering EncodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeBase64 (None) in gradient.\n",
      "tensorflow: Level 1: Registering savers ((<class 'tensorflow.core.protobuf.saver_pb2.SaverDef'>, <function Saver.to_proto at 0x128936f28>, <function Saver.from_proto at 0x128937048>)) in proto functions.\n",
      "tensorflow: Level 1: Registering ReduceDataset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D,flops (<function _calc_conv_flops at 0x128a57510>) in statistical functions.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative,flops (<function _calc_depthwise_conv_flops at 0x128a57598>) in statistical functions.\n",
      "tensorflow: Level 1: Registering BiasAdd,flops (<function _calc_bias_add_flops at 0x128a57620>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Dilation2D,flops (<function _calc_dilation2d_flops at 0x128a591e0>) in statistical functions.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput (<function _Conv2DBackpropInputGrad at 0x128a59488>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter (<function _Conv2DBackpropFilterGrad at 0x128a596a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3D (<function _Conv3DGrad at 0x128a59730>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropInputV2 (<function _Conv3DBackpropInputGrad at 0x128a597b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv3DBackpropFilterV2 (<function _Conv3DBackpropFilterGrad at 0x128a59840>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3D (<function _AvgPool3DGrad at 0x128a598c8>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool3DGrad (<function _AvgPool3DGradGrad at 0x128a59950>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3D (<function _MaxPool3DGrad at 0x128a599d8>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGrad (<function _MaxPool3DGradGrad at 0x128a59a60>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool3DGradGrad (<function _MaxPool3DGradGradGrad at 0x128a59ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Softmax (<function _SoftmaxGrad at 0x128a59b70>) in gradient.\n",
      "tensorflow: Level 1: Registering LogSoftmax (<function _LogSoftmaxGrad at 0x128a59bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAdd (<function _BiasAddGrad at 0x128a59c80>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddGrad (<function _BiasAddGradGrad at 0x128a59d08>) in gradient.\n",
      "tensorflow: Level 1: Registering BiasAddV1 (<function _BiasAddGradV1 at 0x128a59d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu (<function _ReluGrad at 0x128a59e18>) in gradient.\n",
      "tensorflow: Level 1: Registering EluGrad (<function _EluGradGrad at 0x128a59ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering SeluGrad (<function _SeluGradGrad at 0x128a59f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6 (<function _Relu6Grad at 0x128a71048>) in gradient.\n",
      "tensorflow: Level 1: Registering Relu6Grad (<function _Relu6GradGrad at 0x128a710d0>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyRelu (<function _LeakyReluGrad at 0x128a71158>) in gradient.\n",
      "tensorflow: Level 1: Registering LeakyReluGrad (<function _LeakyReluGradGrad at 0x128a711e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Elu (<function _EluGrad at 0x128a71268>) in gradient.\n",
      "tensorflow: Level 1: Registering Selu (<function _SeluGrad at 0x128a71378>) in gradient.\n",
      "tensorflow: Level 1: Registering Softplus (<function _SoftplusGrad at 0x128a71400>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftplusGrad (<function _SoftplusGradGrad at 0x128a71488>) in gradient.\n",
      "tensorflow: Level 1: Registering Softsign (<function _SoftsignGrad at 0x128a71510>) in gradient.\n",
      "tensorflow: Level 1: Registering ReluGrad (<function _ReluGradGrad at 0x128a71598>) in gradient.\n",
      "tensorflow: Level 1: Registering SoftmaxCrossEntropyWithLogits (<function _SoftmaxCrossEntropyWithLogitsGrad at 0x128a716a8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmaxCrossEntropyWithLogits (<function _SparseSoftmaxCrossEntropyWithLogitsGrad at 0x128a71730>) in gradient.\n",
      "tensorflow: Level 1: Registering Conv2D (<function _Conv2DGrad at 0x128a717b8>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthwiseConv2dNative (<function _DepthwiseConv2dNativeGrad at 0x128a71840>) in gradient.\n",
      "tensorflow: Level 1: Registering Dilation2D (<function _Dilation2DGrad at 0x128a718c8>) in gradient.\n",
      "tensorflow: Level 1: Registering LRN (<function _LRNGrad at 0x128a71950>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPool (<function _AvgPoolGrad at 0x128a71a60>) in gradient.\n",
      "tensorflow: Level 1: Registering AvgPoolGrad (<function _AvgPoolGradGrad at 0x128a71ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPool (<function _MaxPoolGrad at 0x128a71b70>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolV2 (<function _MaxPoolGradV2 at 0x128a71bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolWithArgmax (<function _MaxPoolGradWithArgmax at 0x128a71c80>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGrad (<function _MaxPoolGradGrad at 0x128a71d08>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradV2 (<function _MaxPoolGradGradV2 at 0x128a71d90>) in gradient.\n",
      "tensorflow: Level 1: Registering MaxPoolGradGrad (<function _MaxPoolGradGradGrad at 0x128a71e18>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalMaxPool (<function _FractionalMaxPoolGrad at 0x128a71ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering FractionalAvgPool (<function _FractionalAvgPoolGrad at 0x128a71f28>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchNormWithGlobalNormalization (<function _BatchNormWithGlobalNormalizationGrad at 0x128a76048>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNorm (<function _FusedBatchNormGrad at 0x128a76158>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormV2 (<function _FusedBatchNormV2Grad at 0x128a761e0>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGrad (<function _FusedBatchNormGradGrad at 0x128a762f0>) in gradient.\n",
      "tensorflow: Level 1: Registering FusedBatchNormGradV2 (<function _FusedBatchNormGradGradV2 at 0x128a76378>) in gradient.\n",
      "tensorflow: Level 1: Registering L2Loss (<function _L2LossGrad at 0x128a76400>) in gradient.\n",
      "tensorflow: Level 1: Registering TopKV2 (<function _TopKGrad at 0x128a76488>) in gradient.\n",
      "tensorflow: Level 1: Registering TopK (<function _TopKGrad at 0x128a76488>) in gradient.\n",
      "tensorflow: Level 1: Registering NthElement (<function _NthElementGrad at 0x128a76510>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCLoss (<function _CTCLossGrad at 0x128a76598>) in gradient.\n",
      "tensorflow: Level 1: Registering CTCGreedyDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering CTCBeamSearchDecoder (None) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicPartition (<function _DynamicPartitionGrads at 0x128a777b8>) in gradient.\n",
      "tensorflow: Level 1: Registering ParallelDynamicStitch (<function _DynamicStitchGrads at 0x128a77d90>) in gradient.\n",
      "tensorflow: Level 1: Registering DynamicStitch (<function _DynamicStitchGrads at 0x128a77d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Queue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueEnqueueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeue (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueMany (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueDequeueUpTo (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering QueueSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering Stack (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPush (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackPop (None) in gradient.\n",
      "tensorflow: Level 1: Registering StackClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandle (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionHandleV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering GetSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering DeleteSessionTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SetSize (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToDenseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering DenseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToSparseSetOperation (None) in gradient.\n",
      "tensorflow: Level 1: Registering NcclAllReduce (<function _all_sum_grad at 0x128b21620>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclReduce (<function _reduce_sum_grad at 0x128b218c8>) in gradient.\n",
      "tensorflow: Level 1: Registering NcclBroadcast (<function _broadcast_grad at 0x128b219d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Pack (<function _PackGrad at 0x128b7bd90>) in gradient.\n",
      "tensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x128b98158>) in gradient.\n",
      "tensorflow: Level 1: Registering Concat (<function _ConcatGrad at 0x128b98268>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatV2 (<function _ConcatGradV2 at 0x128b982f0>) in gradient.\n",
      "tensorflow: Level 1: Registering ConcatOffset (None) in gradient.\n",
      "tensorflow: Level 1: Registering Slice (<function _SliceGrad at 0x128b98378>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSlice (<function _StridedSliceGrad at 0x128b98400>) in gradient.\n",
      "tensorflow: Level 1: Registering StridedSliceGrad (<function _StridedSliceGradGrad at 0x128b98488>) in gradient.\n",
      "tensorflow: Level 1: Registering Split (<function _SplitGrad at 0x128b98510>) in gradient.\n",
      "tensorflow: Level 1: Registering SplitV (<function _SplitVGrad at 0x128b98598>) in gradient.\n",
      "tensorflow: Level 1: Registering Const (None) in gradient.\n",
      "tensorflow: Level 1: Registering Diag (<function _DiagGrad at 0x128b98620>) in gradient.\n",
      "tensorflow: Level 1: Registering DiagPart (<function _DiagPartGrad at 0x128b986a8>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiag (<function _MatrixDiagGrad at 0x128b98730>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDiagPart (<function _MatrixDiagPartGrad at 0x128b987b8>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSetDiag (<function _MatrixSetDiagGrad at 0x128b98840>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixBandPart (<function _MatrixBandPartGrad at 0x128b988c8>) in gradient.\n",
      "tensorflow: Level 1: Registering EditDistance (None) in gradient.\n",
      "tensorflow: Level 1: Registering Fill (<function _FillGrad at 0x128b98950>) in gradient.\n",
      "tensorflow: Level 1: Registering ZerosLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering OnesLike (None) in gradient.\n",
      "tensorflow: Level 1: Registering PreventGradient (<function _PreventGradientGrad at 0x128b989d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Gather (<function _GatherGrad at 0x128b98a60>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherV2 (<function _GatherV2Grad at 0x128b98ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering GatherNd (<function _GatherNdGrad at 0x128b98b70>) in gradient.\n",
      "tensorflow: Level 1: Registering CheckNumerics (<function _CheckNumericsGrad at 0x128b98bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering Identity (<function _IdGrad at 0x128b98c80>) in gradient.\n",
      "tensorflow: Level 1: Registering PlaceholderWithDefault (<function _IdGrad at 0x128b98c80>) in gradient.\n",
      "tensorflow: Level 1: Registering RefIdentity (<function _RefIdGrad at 0x128b98d08>) in gradient.\n",
      "tensorflow: Level 1: Registering IdentityN (<function _IdNGrad at 0x128b98d90>) in gradient.\n",
      "tensorflow: Level 1: Registering StopGradient (None) in gradient.\n",
      "tensorflow: Level 1: Registering Reshape (<function _ReshapeGrad at 0x128b98e18>) in gradient.\n",
      "tensorflow: Level 1: Registering InvertPermutation (None) in gradient.\n",
      "tensorflow: Level 1: Registering ExpandDims (<function _ExpandDimsGrad at 0x128b98f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Squeeze (<function _SqueezeGrad at 0x128baa048>) in gradient.\n",
      "tensorflow: Level 1: Registering Transpose (<function _TransposeGrad at 0x128baa0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering ConjugateTranspose (<function _ConjugateTransposeGrad at 0x128baa158>) in gradient.\n",
      "tensorflow: Level 1: Registering Shape (None) in gradient.\n",
      "tensorflow: Level 1: Registering ShapeN (None) in gradient.\n",
      "tensorflow: Level 1: Registering Rank (None) in gradient.\n",
      "tensorflow: Level 1: Registering Size (None) in gradient.\n",
      "tensorflow: Level 1: Registering Tile (<function _TileGrad at 0x128baa1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastGradientArgs (None) in gradient.\n",
      "tensorflow: Level 1: Registering Pad (<function _PadGrad at 0x128baa268>) in gradient.\n",
      "tensorflow: Level 1: Registering PadV2 (<function _PadGrad at 0x128baa268>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseSequence (<function _ReverseSequenceGrad at 0x128baa378>) in gradient.\n",
      "tensorflow: Level 1: Registering Reverse (<function _ReverseGrad at 0x128baa400>) in gradient.\n",
      "tensorflow: Level 1: Registering ReverseV2 (<function _ReverseV2Grad at 0x128baa488>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatch (<function _SpaceToBatchGrad at 0x128baa510>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToBatchND (<function _SpaceToBatchNDGrad at 0x128baa598>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpace (<function _BatchToSpaceGrad at 0x128baa620>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchToSpaceND (<function _BatchToSpaceNDGrad at 0x128baa6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering SpaceToDepth (<function _SpaceToDepthGrad at 0x128baa730>) in gradient.\n",
      "tensorflow: Level 1: Registering DepthToSpace (<function _DepthToSpaceGrad at 0x128baa7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering OneHot (None) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPad (<function _MirrorPadGrad at 0x128baa840>) in gradient.\n",
      "tensorflow: Level 1: Registering MirrorPadGrad (<function _MirrorPadGradGrad at 0x128baa8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantize (<function _QuantizeAndDequantizeGrad at 0x128baa950>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV2 (<function _QuantizeAndDequantizeV2Grad at 0x128baa9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering QuantizeAndDequantizeV3 (<function _QuantizeAndDequantizeV3Grad at 0x128baaa60>) in gradient.\n",
      "tensorflow: Level 1: Registering ExtractImagePatches (<function _ExtractImagePatchesGrad at 0x128baaae8>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNd (<function _ScatterNdGrad at 0x128baab70>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterUpdate (<function _TensorScatterUpdateGrad at 0x128baabf8>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterAdd (<function _TensorScatterAddGrad at 0x128baac80>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorScatterSub (<function _TensorScatterSubGrad at 0x128baad08>) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdNonAliasingAdd (<function _ScatterNdNonAliasingAddGrad at 0x128baad90>) in gradient.\n",
      "tensorflow: Level 1: Registering BroadcastTo (<function _BroadcastToGrad at 0x128baae18>) in gradient.\n",
      "tensorflow: Level 1: Registering Switch (<function _SwitchGrad at 0x128baaea0>) in gradient.\n",
      "tensorflow: Level 1: Registering RefSwitch (<function _SwitchGrad at 0x128baaea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Merge (<function _MergeGrad at 0x128baaf28>) in gradient.\n",
      "tensorflow: Level 1: Registering RefMerge (<function _RefMergeGrad at 0x128bb4048>) in gradient.\n",
      "tensorflow: Level 1: Registering Exit (<function _ExitGrad at 0x128bb40d0>) in gradient.\n",
      "tensorflow: Level 1: Registering RefExit (<function _ExitGrad at 0x128bb40d0>) in gradient.\n",
      "tensorflow: Level 1: Registering NextIteration (<function _NextIterationGrad at 0x128bb4158>) in gradient.\n",
      "tensorflow: Level 1: Registering RefNextIteration (<function _RefNextIterationGrad at 0x128bb41e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Enter (<function _EnterGrad at 0x128bb4268>) in gradient.\n",
      "tensorflow: Level 1: Registering RefEnter (<function _RefEnterGrad at 0x128bb42f0>) in gradient.\n",
      "tensorflow: Level 1: Registering LoopCond (<function _LoopCondGrad at 0x128bb4378>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeNearestNeighbor (<function _ResizeNearestNeighborGrad at 0x128bb4400>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBilinear (<function _ResizeBilinearGrad at 0x128bd5488>) in gradient.\n",
      "tensorflow: Level 1: Registering ResizeBicubic (<function _ResizeBicubicGrad at 0x128bd5510>) in gradient.\n",
      "tensorflow: Level 1: Registering CropAndResize (<function _CropAndResizeGrad at 0x128bd5598>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixInverse (<function _MatrixInverseGrad at 0x128bd5620>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixDeterminant (<function _MatrixDeterminantGrad at 0x128bd59d8>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSquareRoot (<function _MatrixSquareRootGrad at 0x128bf6598>) in gradient.\n",
      "tensorflow: Level 1: Registering LogMatrixDeterminant (<function _LogMatrixDeterminantGrad at 0x128bf6620>) in gradient.\n",
      "tensorflow: Level 1: Registering Cholesky (<function _CholeskyGrad at 0x128bf66a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Qr (<function _QrGrad at 0x128bf6730>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolve (<function _MatrixSolveGrad at 0x128bf6840>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixSolveLs (<function _MatrixSolveLsGrad at 0x128bf68c8>) in gradient.\n",
      "tensorflow: Level 1: Registering MatrixTriangularSolve (<function _MatrixTriangularSolveGrad at 0x128bf6950>) in gradient.\n",
      "tensorflow: Level 1: Registering SelfAdjointEigV2 (<function _SelfAdjointEigV2Grad at 0x128bf69d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Svd (<function _SvdGrad at 0x128bf6a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Print (<function _PrintGrad at 0x128bf6e18>) in gradient.\n",
      "tensorflow: Level 1: Registering HistogramSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ImageSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering AudioSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering MergeSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScalarSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummary (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorSummaryV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering Timestamp (None) in gradient.\n",
      "tensorflow: Level 1: Registering Roll (<function _RollGrad at 0x128c00598>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMax (<function _ArgMaxGrad at 0x128c142f0>) in gradient.\n",
      "tensorflow: Level 1: Registering ArgMin (<function _ArgMinGrad at 0x128c14378>) in gradient.\n",
      "tensorflow: Level 1: Registering Sum (<function _SumGrad at 0x128c14400>) in gradient.\n",
      "tensorflow: Level 1: Registering Max (<function _MaxGrad at 0x128c14598>) in gradient.\n",
      "tensorflow: Level 1: Registering Min (<function _MinGrad at 0x128c146a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Mean (<function _MeanGrad at 0x128c147b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Prod (<function _ProdGrad at 0x128c14840>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentSum (<function _SegmentSumGrad at 0x128c148c8>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMean (<function _SegmentMeanGrad at 0x128c14950>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSum (<function _SparseSegmentSumGrad at 0x128c149d8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSumWithNumSegments (<function _SparseSegmentSumWithNumSegmentsGrad at 0x128c14a60>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMean (<function _SparseSegmentMeanGrad at 0x128c14ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentMeanWithNumSegments (<function _SparseSegmentMeanWithNumSegmentsGrad at 0x128c14b70>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtN (<function _SparseSegmentSqrtNGrad at 0x128c14bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSegmentSqrtNWithNumSegments (<function _SparseSegmentSqrtNWithNumSegmentsGrad at 0x128c14c80>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMin (<function _SegmentMinGrad at 0x128c14d90>) in gradient.\n",
      "tensorflow: Level 1: Registering SegmentMax (<function _SegmentMaxGrad at 0x128c14e18>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentSum (<function _UnsortedSegmentSumGrad at 0x128c1b048>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMax (<function _UnsortedSegmentMaxGrad at 0x128c1b0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentMin (<function _UnsortedSegmentMinGrad at 0x128c1b158>) in gradient.\n",
      "tensorflow: Level 1: Registering UnsortedSegmentProd (<function _UnsortedSegmentProdGrad at 0x128c1b1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Abs (<function _AbsGrad at 0x128c1b268>) in gradient.\n",
      "tensorflow: Level 1: Registering Neg (<function _NegGrad at 0x128c1b378>) in gradient.\n",
      "tensorflow: Level 1: Registering Inv (<function _InvGrad at 0x128c1b488>) in gradient.\n",
      "tensorflow: Level 1: Registering Reciprocal (<function _ReciprocalGrad at 0x128c1b598>) in gradient.\n",
      "tensorflow: Level 1: Registering InvGrad (<function _InvGradGrad at 0x128c1b620>) in gradient.\n",
      "tensorflow: Level 1: Registering ReciprocalGrad (<function _ReciprocalGradGrad at 0x128c1b6a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Square (<function _SquareGrad at 0x128c1b730>) in gradient.\n",
      "tensorflow: Level 1: Registering Sqrt (<function _SqrtGrad at 0x128c1b7b8>) in gradient.\n",
      "tensorflow: Level 1: Registering SqrtGrad (<function _SqrtGradGrad at 0x128c1b840>) in gradient.\n",
      "tensorflow: Level 1: Registering Rsqrt (<function _RsqrtGrad at 0x128c1b8c8>) in gradient.\n",
      "tensorflow: Level 1: Registering RsqrtGrad (<function _RsqrtGradGrad at 0x128c1b950>) in gradient.\n",
      "tensorflow: Level 1: Registering Exp (<function _ExpGrad at 0x128c1b9d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Expm1 (<function _Expm1Grad at 0x128c1bae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Log (<function _LogGrad at 0x128c1bb70>) in gradient.\n",
      "tensorflow: Level 1: Registering Log1p (<function _Log1pGrad at 0x128c1bc80>) in gradient.\n",
      "tensorflow: Level 1: Registering Xlogy (<function _XLogyGrad at 0x128c1bd08>) in gradient.\n",
      "tensorflow: Level 1: Registering Xdivy (<function _XDivyGrad at 0x128c1bd90>) in gradient.\n",
      "tensorflow: Level 1: Registering Sinh (<function _SinhGrad at 0x128c1be18>) in gradient.\n",
      "tensorflow: Level 1: Registering Cosh (<function _CoshGrad at 0x128c1bea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Tanh (<function _TanhGrad at 0x128c1bf28>) in gradient.\n",
      "tensorflow: Level 1: Registering Asinh (<function _AsinhGrad at 0x128c23048>) in gradient.\n",
      "tensorflow: Level 1: Registering Acosh (<function _AcoshGrad at 0x128c230d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Atanh (<function _AtanhGrad at 0x128c23158>) in gradient.\n",
      "tensorflow: Level 1: Registering TanhGrad (<function _TanhGradGrad at 0x128c231e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Erf (<function _ErfGrad at 0x128c23268>) in gradient.\n",
      "tensorflow: Level 1: Registering Erfc (<function _ErfcGrad at 0x128c23378>) in gradient.\n",
      "tensorflow: Level 1: Registering Lgamma (<function _LgammaGrad at 0x128c23400>) in gradient.\n",
      "tensorflow: Level 1: Registering Digamma (<function _DigammaGrad at 0x128c23488>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI0e (<function _BesselI0eGrad at 0x128c23510>) in gradient.\n",
      "tensorflow: Level 1: Registering BesselI1e (<function _BesselI1eGrad at 0x128c23598>) in gradient.\n",
      "tensorflow: Level 1: Registering Igamma (<function _IgammaGrad at 0x128c23620>) in gradient.\n",
      "tensorflow: Level 1: Registering Igammac (<function _IgammacGrad at 0x128c236a8>) in gradient.\n",
      "tensorflow: Level 1: Registering Betainc (<function _BetaincGrad at 0x128c23730>) in gradient.\n",
      "tensorflow: Level 1: Registering Zeta (<function _ZetaGrad at 0x128c237b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Polygamma (<function _PolygammaGrad at 0x128c23840>) in gradient.\n",
      "tensorflow: Level 1: Registering Sigmoid (<function _SigmoidGrad at 0x128c238c8>) in gradient.\n",
      "tensorflow: Level 1: Registering SigmoidGrad (<function _SigmoidGradGrad at 0x128c23950>) in gradient.\n",
      "tensorflow: Level 1: Registering Sign (<function _SignGrad at 0x128c239d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Sin (<function _SinGrad at 0x128c23a60>) in gradient.\n",
      "tensorflow: Level 1: Registering Cos (<function _CosGrad at 0x128c23b70>) in gradient.\n",
      "tensorflow: Level 1: Registering Tan (<function _TanGrad at 0x128c23c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Asin (<function _AsinGrad at 0x128c23d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Acos (<function _AcosGrad at 0x128c23e18>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan (<function _AtanGrad at 0x128c23ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering Atan2 (<function _Atan2Grad at 0x128c23f28>) in gradient.\n",
      "tensorflow: Level 1: Registering AddN (<function _AddNGrad at 0x128c21048>) in gradient.\n",
      "tensorflow: Level 1: Registering Add (<function _AddGrad at 0x128c21158>) in gradient.\n",
      "tensorflow: Level 1: Registering Sub (<function _SubGrad at 0x128c21268>) in gradient.\n",
      "tensorflow: Level 1: Registering Mul (<function _MulGrad at 0x128c21378>) in gradient.\n",
      "tensorflow: Level 1: Registering Div (<function _DivGrad at 0x128c21488>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorDiv (<function _FloorDivGrad at 0x128c21598>) in gradient.\n",
      "tensorflow: Level 1: Registering FloorMod (<function _FloorModGrad at 0x128c21620>) in gradient.\n",
      "tensorflow: Level 1: Registering TruncateDiv (<function _TruncateDivGrad at 0x128c216a8>) in gradient.\n",
      "tensorflow: Level 1: Registering RealDiv (<function _RealDivGrad at 0x128c21730>) in gradient.\n",
      "tensorflow: Level 1: Registering DivNoNan (<function _DivNoNanGrad at 0x128c217b8>) in gradient.\n",
      "tensorflow: Level 1: Registering Pow (<function _PowGrad at 0x128c21840>) in gradient.\n",
      "tensorflow: Level 1: Registering Maximum (<function _MaximumGrad at 0x128c219d8>) in gradient.\n",
      "tensorflow: Level 1: Registering Minimum (<function _MinimumGrad at 0x128c21a60>) in gradient.\n",
      "tensorflow: Level 1: Registering SquaredDifference (<function _SquaredDifferenceGrad at 0x128c21ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Less (None) in gradient.\n",
      "tensorflow: Level 1: Registering LessEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Greater (None) in gradient.\n",
      "tensorflow: Level 1: Registering GreaterEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering Equal (None) in gradient.\n",
      "tensorflow: Level 1: Registering ApproximateEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering NotEqual (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalAnd (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalOr (None) in gradient.\n",
      "tensorflow: Level 1: Registering LogicalNot (None) in gradient.\n",
      "tensorflow: Level 1: Registering Select (<function _SelectGrad at 0x128c21b70>) in gradient.\n",
      "tensorflow: Level 1: Registering MatMul (<function _MatMulGrad at 0x128c21bf8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseMatMul (<function _SparseMatMulGrad at 0x128c21c80>) in gradient.\n",
      "tensorflow: Level 1: Registering Floor (<function _FloorGrad at 0x128c21d08>) in gradient.\n",
      "tensorflow: Level 1: Registering Ceil (<function _CeilGrad at 0x128c21d90>) in gradient.\n",
      "tensorflow: Level 1: Registering Round (<function _RoundGrad at 0x128c21e18>) in gradient.\n",
      "tensorflow: Level 1: Registering Rint (<function _RintGrad at 0x128c21ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering BatchMatMul (<function _BatchMatMul at 0x128c21f28>) in gradient.\n",
      "tensorflow: Level 1: Registering Range (None) in gradient.\n",
      "tensorflow: Level 1: Registering LinSpace (None) in gradient.\n",
      "tensorflow: Level 1: Registering Complex (<function _ComplexGrad at 0x128c2e048>) in gradient.\n",
      "tensorflow: Level 1: Registering Real (<function _RealGrad at 0x128c2e0d0>) in gradient.\n",
      "tensorflow: Level 1: Registering Imag (<function _ImagGrad at 0x128c2e158>) in gradient.\n",
      "tensorflow: Level 1: Registering Angle (<function _AngleGrad at 0x128c2e1e0>) in gradient.\n",
      "tensorflow: Level 1: Registering Conj (<function _ConjGrad at 0x128c2e268>) in gradient.\n",
      "tensorflow: Level 1: Registering ComplexAbs (<function _ComplexAbsGrad at 0x128c2e2f0>) in gradient.\n",
      "tensorflow: Level 1: Registering Cast (<function _CastGrad at 0x128c2e378>) in gradient.\n",
      "tensorflow: Level 1: Registering Cross (<function _CrossGrad at 0x128c2e400>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumsum (<function _CumsumGrad at 0x128c2e488>) in gradient.\n",
      "tensorflow: Level 1: Registering Cumprod (<function _CumprodGrad at 0x128c2e510>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalFromValue (<function _OptionalFromValueGrad at 0x128c2e598>) in gradient.\n",
      "tensorflow: Level 1: Registering OptionalGetValue (<function _OptionalGetValueGrad at 0x128c2e620>) in gradient.\n",
      "tensorflow: Level 1: Registering RandomGamma (<function _RandomGammaGrad at 0x128c2e730>) in gradient.\n",
      "tensorflow: Level 1: Registering DecodeRaw (None) in gradient.\n",
      "tensorflow: Level 1: Registering ParseTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering SerializeTensor (None) in gradient.\n",
      "tensorflow: Level 1: Registering StringToNumber (None) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNN (<function _cudnn_rnn_backward at 0x1284a3ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering CudnnRNNV2 (<function _cudnn_rnn_backward_v2 at 0x128db0268>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAddGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseConcat (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseToDense (None) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReorder (<function _SparseReorderGrad at 0x128db02f0>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseAdd (<function _SparseAddGrad at 0x128db0488>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseAdd (<function _SparseTensorDenseAddGrad at 0x128db0510>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseReduceSum (<function _SparseReduceSumGrad at 0x128db0598>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSlice (<function _SparseSliceGrad at 0x128db0620>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseTensorDenseMatMul (<function _SparseTensorDenseMatMulGrad at 0x128db06a8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseAdd (<function _SparseDenseCwiseAddGrad at 0x128db0730>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseMul (<function _SparseDenseCwiseMulGrad at 0x128db0840>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseDenseCwiseDiv (<function _SparseDenseCwiseDivGrad at 0x128db08c8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSoftmax (<function _SparseSoftmaxGrad at 0x128db0950>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMaximum (<function _SparseSparseMaximumGrad at 0x128db09d8>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseSparseMinimum (<function _SparseSparseMinimumGrad at 0x128db0a60>) in gradient.\n",
      "tensorflow: Level 1: Registering SparseFillEmptyRows (<function _SparseFillEmptyRowsGrad at 0x128db0ae8>) in gradient.\n",
      "tensorflow: Level 1: Registering Assign (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering AssignSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdUpdate (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdAdd (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdSub (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdMul (None) in gradient.\n",
      "tensorflow: Level 1: Registering ScatterNdDiv (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArray (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGrad (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySize (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayClose (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV2 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGradWithShape (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArraySizeV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayCloseV3 (None) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV3 (<function _TensorArrayReadGrad at 0x128db0d90>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayReadV2 (<function _TensorArrayReadGrad at 0x128db0d90>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayRead (<function _TensorArrayReadGrad at 0x128db0d90>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV3 (<function _TensorArrayWriteGrad at 0x128db0e18>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWriteV2 (<function _TensorArrayWriteGrad at 0x128db0e18>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayWrite (<function _TensorArrayWriteGrad at 0x128db0e18>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV3 (<function _TensorArrayGatherGrad at 0x128db0ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGatherV2 (<function _TensorArrayGatherGrad at 0x128db0ea0>) in gradient.\n",
      "tensorflow: Level 1: Registering TensorArrayGather (<function _TensorArrayGatherGrad at 0x128db0ea0>) in gradient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: Level 1: Registering TensorArrayScatterV3 (<function _TensorArrayScatterGrad at 0x128db0f28>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArrayScatterV2 (<function _TensorArrayScatterGrad at 0x128db0f28>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArrayScatter (<function _TensorArrayScatterGrad at 0x128db0f28>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV3 (<function _TensorArrayConcatGrad at 0x128dc4048>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArrayConcatV2 (<function _TensorArrayConcatGrad at 0x128dc4048>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArrayConcat (<function _TensorArrayConcatGrad at 0x128dc4048>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArraySplitV3 (<function _TensorArraySplitGrad at 0x128dc40d0>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArraySplitV2 (<function _TensorArraySplitGrad at 0x128dc40d0>) in gradient.\r\n",
      "tensorflow: Level 1: Registering TensorArraySplit (<function _TensorArraySplitGrad at 0x128dc40d0>) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableFind (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableFindV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableInsert (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableInsertV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableSize (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LookupTableSizeV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering HashTable (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering HashTableV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering InitializeTable (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering InitializeTableV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFile (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering InitializeTableFromTextFileV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableDenseHashTable (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableDenseHashTableV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableHashTable (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableHashTableV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensors (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering MutableHashTableOfTensorsV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering RaggedTensorToSparse (<function _ragged_tensor_to_sparse_gradient at 0x128e41a60>) in gradient.\r\n",
      "tensorflow: Level 1: Registering StatelessMultinomial (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering StatelessRandomNormal (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering StatelessRandomUniform (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering StatelessRandomUniformInt (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering StatelessTruncatedNormal (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering RandomCrop (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering RGBToHSV (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering HSVToRGB (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering DrawBoundingBoxes (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBox (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering SampleDistortedBoundingBoxV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering ExtractGlimpse (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering NonMaxSuppression (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering NonMaxSuppressionWithOverlaps (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering BitwiseAnd (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering BitwiseOr (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering BitwiseXor (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering Invert (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering PopulationCount (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LeftShift (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering RightShift (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering FFT (<function _fft_grad at 0x13571e620>) in gradient.\r\n",
      "tensorflow: Level 1: Registering IFFT (<function _ifft_grad at 0x13571e730>) in gradient.\r\n",
      "tensorflow: Level 1: Registering FFT2D (<function _fft2d_grad at 0x13571e7b8>) in gradient.\r\n",
      "tensorflow: Level 1: Registering IFFT2D (<function _ifft2d_grad at 0x13571e840>) in gradient.\r\n",
      "tensorflow: Level 1: Registering FFT3D (<function _fft3d_grad at 0x13571e8c8>) in gradient.\r\n",
      "tensorflow: Level 1: Registering IFFT3D (<function _ifft3d_grad at 0x13571e950>) in gradient.\r\n",
      "tensorflow: Level 1: Registering RFFT (<function _rfft_grad_helper.<locals>._grad at 0x13571eae8>) in gradient.\r\n",
      "tensorflow: Level 1: Registering IRFFT (<function _irfft_grad_helper.<locals>._grad at 0x13571eb70>) in gradient.\r\n",
      "tensorflow: Level 1: Registering RFFT2D (<function _rfft_grad_helper.<locals>._grad at 0x13571ebf8>) in gradient.\r\n",
      "tensorflow: Level 1: Registering IRFFT2D (<function _irfft_grad_helper.<locals>._grad at 0x13571ec80>) in gradient.\r\n",
      "tensorflow: Level 1: Registering Reciprocal,flops (<function _reciprocal_flops at 0x135762400>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Square,flops (<function _square_flops at 0x135762488>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Rsqrt,flops (<function _rsqrt_flops at 0x135762510>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Log,flops (<function _log_flops at 0x135762598>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Neg,flops (<function _neg_flops at 0x135762620>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering AssignSub,flops (<function _assign_sub_flops at 0x1357626a8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering AssignAdd,flops (<function _assign_add_flops at 0x135762730>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering L2Loss,flops (<function _l2_loss_flops at 0x1357627b8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Softmax,flops (<function _softmax_flops at 0x135762840>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Add,flops (<function _add_flops at 0x135762950>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Sub,flops (<function _sub_flops at 0x1357629d8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Mul,flops (<function _mul_flops at 0x135762a60>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering RealDiv,flops (<function _real_div_flops at 0x135762ae8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Maximum,flops (<function _maximum_flops at 0x135762b70>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Minimum,flops (<function _minimum_flops at 0x135762bf8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Pow,flops (<function _pow_flops at 0x135762c80>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering RsqrtGrad,flops (<function _rsqrt_grad_flops at 0x135762d08>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering GreaterEqual,flops (<function _greater_equal_flops at 0x135762d90>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Greater,flops (<function _greater_flops at 0x135762e18>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering LessEqual,flops (<function _less_equal_flops at 0x135762ea0>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Less,flops (<function _less_flops at 0x135762f28>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Equal,flops (<function _equal_flops at 0x135775048>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering NotEqual,flops (<function _not_equal_flops at 0x1357750d0>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering SquaredDifference,flops (<function _squared_difference_flops at 0x135775158>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Mean,flops (<function _mean_flops at 0x135775268>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Sum,flops (<function _sum_flops at 0x1357752f0>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering ArgMax,flops (<function _arg_max_flops at 0x135775378>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering ArgMin,flops (<function _arg_min_flops at 0x135775400>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering BiasAddGrad,flops (<function _bias_add_grad_flops at 0x135775488>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering AvgPool,flops (<function _avg_pool_flops at 0x135775620>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering MaxPool,flops (<function _max_pool_flops at 0x1357756a8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering AvgPoolGrad,flops (<function _avg_pool_grad_flops at 0x135775730>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering MaxPoolGrad,flops (<function _max_pool_grad_flops at 0x1357757b8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Conv2DBackpropInput,flops (<function _conv_2d_backprop_input_flops at 0x135775840>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Conv2DBackpropFilter,flops (<function _conv_2d_backprop_filter_flops at 0x1357758c8>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering AddN,flops (<function _add_n_flops at 0x135775950>) in statistical functions.\r\n",
      "tensorflow: Level 1: Registering Fact (<function _set_call_cpp_shape_fn.<locals>.call_without_requiring at 0x127ef2598>) in default shape functions.\r\n",
      "tensorflow: Level 1: Registering SdcaFprint (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering SdcaOptimizer (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering SdcaOptimizerV2 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering SdcaShrinkL1 (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering queue_runners ((<class 'tensorflow.core.protobuf.queue_runner_pb2.QueueRunnerDef'>, <function QueueRunner.to_proto at 0x1357ff1e0>, <function QueueRunner.from_proto at 0x1357ff268>)) in proto functions.\r\n",
      "tensorflow: Level 1: Registering GenerateVocabRemapping (None) in gradient.\r\n",
      "tensorflow: Level 1: Registering LoadAndRemapMatrix (None) in gradient.\r\n",
      "matplotlib: DEBUG: CACHEDIR=/Users/davidmortensen/.matplotlib\r\n",
      "matplotlib.font_manager: DEBUG: Using fontManager instance from /Users/davidmortensen/.matplotlib/fontList.json\r\n",
      "matplotlib.backends: DEBUG: backend module://ipykernel.pylab.backend_inline version unknown\r\n",
      "--------------------- >> end captured logging << ---------------------\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.001s\r\n",
      "\r\n",
      "FAILED (errors=1)\r\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_classifier.py:test_d3_4a_nb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8e039d772727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_smoother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_best_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr_pruned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dv_pruned\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_dv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/naive_bayes.py\u001b[0m in \u001b[0;36mfind_best_smoother\u001b[0;34m(x_tr, y_tr, x_dv, y_dv, smoothers)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmoothers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtheta_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdev_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/clf_base.py\u001b[0m in \u001b[0;36mpredict_all\u001b[0;34m(x, weights, labels)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     '''\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/clf_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     '''\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/clf_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(base_features, weights, labels)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# get active features for a class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mweights_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mactive_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_features\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mactive_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/clf_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# get active features for a class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mweights_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mactive_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mbase_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_features\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mactive_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_smoother, scores = naive_bayes.find_best_smoother(x_tr_pruned,y_tr,x_dv_pruned,y_dv,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(list(scores.keys()),list(scores.values()),'o-');\n",
    "plt.xlabel('smoothing')\n",
    "plt.ylabel('dev set accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect:**\n",
    "\n",
    "- what might explain the dramatic drop in accuracy when the smoothing is increased from $10$ to $30$?\n",
    "- before you check, predict whether the accuracy will continue to significantly drop if you further increase the smoothing to $10000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write out the best predictions for NB\n",
    "theta_nb = naive_bayes.estimate_nb(x_tr_pruned,y_tr,best_smoother)\n",
    "y_hat = clf_base.predict_all(x_te_pruned,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-best-test.preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic regression\n",
    "\n",
    "\n",
    "You will implement logistic regression in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Converting data to numpy\n",
    "\n",
    "Numpy is a package for numerical computing in python.\n",
    "\n",
    "You will need to convert your bag-of-words list of counters to a numpy array. \n",
    "\n",
    "- **Deliverable 4.1**: Implement `preproc.py:make_numpy()` \n",
    "- **Test**: `test_logreg:test_d4_1_numpy`\n",
    "- **Hint**: one approach is to start with `numpy.zeros((height,width))`, and then fill in the cells by iterating through the bag-of-words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nb-best-test.preds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-2fdf82019015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# you can't run this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nb-best-test.preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2ndyearproject/Milestone1/snlp/evaluation.py\u001b[0m in \u001b[0;36mread_predictions\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nb-best-test.preds'"
     ]
    }
   ],
   "source": [
    "# you can't run this\n",
    "y_hat = evaluation.read_predictions('nb-best-test.preds')\n",
    "print(evaluation.acc(y_hat,y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_pruned, vocab = preproc.prune_vocabulary(counts_tr,x_tr,10)\n",
    "x_dv_pruned, _ = preproc.prune_vocabulary(counts_tr,x_dv,10)\n",
    "x_te_pruned, _ = preproc.prune_vocabulary(counts_tr,x_te,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((4,2))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 0.  -1. ]\n",
      " [ 1.5  0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "X[1,1] = -1\n",
    "X[2,0] = 1.5\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = preproc.make_numpy(x_tr_pruned,vocab)\n",
    "X_dv = preproc.make_numpy(x_dv_pruned,vocab)\n",
    "X_te = preproc.make_numpy(x_te_pruned,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the labels in Keras\n",
    "\n",
    "In Keras, the labels need to be mapped to numbers. Moreover, each label has to be encoded in a one-hot vector. It is a vector of the length of all labels, and a 1 indicates which label is the correct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1980s', '1990s', '2000s', 'pre-1980s']\n"
     ]
    }
   ],
   "source": [
    "label_set = sorted(list(set(y_tr)))\n",
    "print(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the label '1990s' would be represented as vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to convert your label list to a numpy array. \n",
    "\n",
    "- **Deliverable 4.2**: Implement `preproc.convert_categ_label_to_vec()` \n",
    "- **Test**: `tests/test_logreg.py:test_d4_2_convert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nose.config: INFO: Ignoring files matching ['^\\\\.', '^_', '^setup\\\\.py$']\n",
      "Using TensorFlow backend.\n",
      "test_logreg.test_d4_2_convert ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 64.515s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_logreg.py:test_d4_2_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = preproc.convert_categ_label_to_vec(y_tr)\n",
    "Y_dv = preproc.convert_categ_label_to_vec(y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(Y_tr[0])==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364528\n",
      "45915\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(X_tr))\n",
    "print(np.count_nonzero(X_dv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Building a logistic regression model\n",
    "\n",
    "- **Deliverable 4.3**: Complete `logreg.build_linear` \n",
    "- **Test**: `tests/test_logreg.py:test_d4_3_logreg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snlp import logreg\n",
    "import random\n",
    "reload(logreg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(765);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to check the dimensions of your data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4135, 5992)\n",
      "(514, 5992)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(X_dv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 5992)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logreg.build_linear(X_tr,Y_tr, 'categorical_crossentropy')\n",
    "X_dv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4135/4135 [==============================] - 2s 510us/step - loss: 3.0146 - acc: 0.4031\n",
      "Epoch 2/5\n",
      "4135/4135 [==============================] - 2s 477us/step - loss: 2.3014 - acc: 0.5057\n",
      "Epoch 3/5\n",
      "4135/4135 [==============================] - 2s 476us/step - loss: 1.8268 - acc: 0.5661\n",
      "Epoch 4/5\n",
      "4135/4135 [==============================] - 2s 482us/step - loss: 1.4593 - acc: 0.6346\n",
      "Epoch 5/5\n",
      "4135/4135 [==============================] - 2s 428us/step - loss: 1.3394 - acc: 0.6612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d7bb748>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, Y_tr, epochs=5, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.37436882e-02 1.55824302e-02 9.20302927e-01 3.70944850e-04]\n",
      " [1.01638637e-01 1.12391459e-02 8.87093842e-01 2.83352420e-05]\n",
      " [3.30058218e-04 7.52629200e-03 9.92129505e-01 1.40608026e-05]\n",
      " ...\n",
      " [7.00875127e-04 1.11955866e-01 7.91016400e-01 9.63268355e-02]\n",
      " [1.14592840e-04 9.19508815e-01 7.83338994e-02 2.04277597e-03]\n",
      " [2.90413260e-01 5.40776290e-02 5.89433312e-01 6.60757646e-02]]\n"
     ]
    }
   ],
   "source": [
    "scores = logreg.forward(model, X_dv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Checking the output layer\n",
    "\n",
    "We have everything in place. Let's check that the output is proper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3743688e-02, 1.5582430e-02, 9.2030293e-01, 3.7094485e-04],\n",
       "       [1.0163864e-01, 1.1239146e-02, 8.8709384e-01, 2.8335242e-05],\n",
       "       [3.3005822e-04, 7.5262920e-03, 9.9212950e-01, 1.4060803e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.forward(model,X_dv)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0658191, 1.0157045, 2.5100505, 1.000371 ],\n",
       "       [1.1069834, 1.0113026, 2.4280632, 1.0000284],\n",
       "       [1.0003301, 1.0075547, 2.6969717, 1.0000141]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = logreg.forward(model,X_dv)[:3]\n",
    "np.exp(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each row has to sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999994, 0.99999994, 0.99999994], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Putting everything together\n",
    "\n",
    "An optimizer can be used to actually learn the weights. We provide the complete code below that you can train on in `logreg.train_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(logreg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a new model with a fixed seed\n",
    "from keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.05)\n",
    "model = logreg.build_linear(X_tr,Y_tr, 'categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4135 samples, validate on 514 samples\n",
      "Epoch 1/30\n",
      "4135/4135 [==============================] - 2s 503us/step - loss: 7.8827 - acc: 0.4102 - val_loss: 7.4286 - val_acc: 0.4611\n",
      "Epoch 2/30\n",
      "4135/4135 [==============================] - 2s 449us/step - loss: 7.0722 - acc: 0.4844 - val_loss: 7.5206 - val_acc: 0.4591\n",
      "Epoch 3/30\n",
      "4135/4135 [==============================] - 2s 453us/step - loss: 6.5780 - acc: 0.5144 - val_loss: 7.2751 - val_acc: 0.4591\n",
      "Epoch 4/30\n",
      "4135/4135 [==============================] - 2s 453us/step - loss: 6.3209 - acc: 0.5316 - val_loss: 6.9358 - val_acc: 0.5039\n",
      "Epoch 5/30\n",
      "4135/4135 [==============================] - 2s 453us/step - loss: 5.9007 - acc: 0.5577 - val_loss: 7.4723 - val_acc: 0.4436\n",
      "Epoch 6/30\n",
      "4135/4135 [==============================] - 2s 455us/step - loss: 5.6714 - acc: 0.5763 - val_loss: 7.3547 - val_acc: 0.4669\n",
      "Epoch 7/30\n",
      "4135/4135 [==============================] - 2s 463us/step - loss: 5.4024 - acc: 0.5973 - val_loss: 7.8506 - val_acc: 0.4416\n",
      "Epoch 8/30\n",
      "4135/4135 [==============================] - 2s 456us/step - loss: 5.1172 - acc: 0.6114 - val_loss: 6.7803 - val_acc: 0.4747\n",
      "Epoch 9/30\n",
      "4135/4135 [==============================] - 2s 470us/step - loss: 5.1171 - acc: 0.6077 - val_loss: 6.5023 - val_acc: 0.5058\n",
      "Epoch 10/30\n",
      "4135/4135 [==============================] - 2s 458us/step - loss: 4.8090 - acc: 0.6295 - val_loss: 6.8232 - val_acc: 0.4922\n",
      "Epoch 11/30\n",
      "4135/4135 [==============================] - 2s 455us/step - loss: 4.7885 - acc: 0.6370 - val_loss: 6.6588 - val_acc: 0.5058\n",
      "Epoch 12/30\n",
      "4135/4135 [==============================] - 2s 460us/step - loss: 4.6519 - acc: 0.6435 - val_loss: 6.7815 - val_acc: 0.4922\n",
      "Epoch 13/30\n",
      "4135/4135 [==============================] - 2s 463us/step - loss: 4.5389 - acc: 0.6476 - val_loss: 7.7548 - val_acc: 0.4183\n",
      "Epoch 14/30\n",
      "4135/4135 [==============================] - 2s 468us/step - loss: 4.2183 - acc: 0.6742 - val_loss: 6.4348 - val_acc: 0.5039\n",
      "Epoch 15/30\n",
      "4135/4135 [==============================] - 2s 467us/step - loss: 3.9812 - acc: 0.6890 - val_loss: 7.4202 - val_acc: 0.4455\n",
      "Epoch 16/30\n",
      "4135/4135 [==============================] - 2s 469us/step - loss: 4.0159 - acc: 0.6837 - val_loss: 7.3703 - val_acc: 0.4436\n",
      "Epoch 17/30\n",
      "4135/4135 [==============================] - 2s 468us/step - loss: 3.8722 - acc: 0.6921 - val_loss: 6.8158 - val_acc: 0.5019\n",
      "Epoch 18/30\n",
      "4135/4135 [==============================] - 2s 463us/step - loss: 3.6133 - acc: 0.7161 - val_loss: 6.7183 - val_acc: 0.5039\n",
      "Epoch 19/30\n",
      "4135/4135 [==============================] - 2s 461us/step - loss: 3.6368 - acc: 0.7149 - val_loss: 6.8532 - val_acc: 0.4961\n",
      "Epoch 20/30\n",
      "4135/4135 [==============================] - 2s 458us/step - loss: 3.6054 - acc: 0.7129 - val_loss: 6.6763 - val_acc: 0.5117\n",
      "Epoch 21/30\n",
      "4135/4135 [==============================] - 2s 464us/step - loss: 3.3555 - acc: 0.7277 - val_loss: 6.4131 - val_acc: 0.5195\n",
      "Epoch 22/30\n",
      "4135/4135 [==============================] - 2s 466us/step - loss: 3.2800 - acc: 0.7407 - val_loss: 6.4548 - val_acc: 0.5272\n",
      "Epoch 23/30\n",
      "4135/4135 [==============================] - 2s 455us/step - loss: 3.0192 - acc: 0.7574 - val_loss: 6.6761 - val_acc: 0.5000\n",
      "Epoch 24/30\n",
      "4135/4135 [==============================] - 2s 458us/step - loss: 2.9876 - acc: 0.7582 - val_loss: 7.2618 - val_acc: 0.4961\n",
      "Epoch 25/30\n",
      "4135/4135 [==============================] - 2s 473us/step - loss: 3.0341 - acc: 0.7550 - val_loss: 6.8202 - val_acc: 0.5117\n",
      "Epoch 26/30\n",
      "4135/4135 [==============================] - 2s 464us/step - loss: 2.8994 - acc: 0.7719 - val_loss: 6.5114 - val_acc: 0.5156\n",
      "Epoch 27/30\n",
      "4135/4135 [==============================] - 2s 465us/step - loss: 2.7751 - acc: 0.7758 - val_loss: 6.4560 - val_acc: 0.5097\n",
      "Epoch 28/30\n",
      "4135/4135 [==============================] - 2s 457us/step - loss: 2.6334 - acc: 0.7884 - val_loss: 6.4341 - val_acc: 0.5117\n",
      "Epoch 29/30\n",
      "4135/4135 [==============================] - 2s 455us/step - loss: 2.5880 - acc: 0.7944 - val_loss: 6.6805 - val_acc: 0.4767\n",
      "Epoch 30/30\n",
      "4135/4135 [==============================] - 2s 457us/step - loss: 2.5301 - acc: 0.7911 - val_loss: 6.1902 - val_acc: 0.5292\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_tr, Y_tr, validation_data=(X_dv,Y_dv), epochs=30, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspect the hist object to find out how to plot the graphs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-185-525c3f757fa8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-185-525c3f757fa8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    losses = pass\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "losses = pass\n",
    "accuracies = pass\n",
    "logreg.plot_results(losses,accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4.5**\n",
    "The noisy progress of the loss and dev set accuracy suggests that something is wrong with our hyperparameters. Tune the inputs to `train_model` until you can get to a dev set accuracy of at least 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = logreg.forward(model, X_dv)\n",
    "# write the results to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation\n",
    "\n",
    "**Deliverable 7.1**: Try to do a better evaluation. What other metrics might be more informative here?\n",
    "    \n",
    "**Deliverable 7.2**: Create a confusion matrix. Which classes are often confused?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Best classifier\n",
    "\n",
    "**Deliverable 8.1**: Try to get the best accuracy possible. \n",
    "\n",
    "Some ideas:\n",
    "\n",
    "- Better features or representations\n",
    "- Better optimization\n",
    "- Better classifier, e.g. multilayer neural networks\n",
    "- Better loss function\n",
    "- Better preprocessing\n",
    "- Better regularization\n",
    "\n",
    "Use the lectures and reading material as further inspiration.\n",
    "\n",
    "Keep in mind that you can always:\n",
    "- Look at the predictive features\n",
    "- Add more features (of other sorts)\n",
    "\n",
    "\n",
    "\n",
    "**Deliverable 8.2**: Submit the results of your final best classifier on the held-out data (`hidden`). Upload your result (see milestone 1 instructions), as well as a link to your github repository and a one slide summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsproj0XX-m1-predictions.txt\n"
     ]
    }
   ],
   "source": [
    "## code to write your result file, name it with your username\n",
    "\n",
    "output_filename = \"{}-m1-predictions.txt\".format(username)\n",
    "print(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to upload also your one slide summary of your work on this milestone. What results did you obtain? What worked (or didn't?) How was the evaluation affected by your choices? Be creative! "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
